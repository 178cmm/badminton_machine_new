"""
ğŸ¸ ç¾½çƒç™¼çƒæ©ŸèªéŸ³æ§åˆ¶ç³»çµ± - TTS æ•´åˆç‰ˆ
æ•´åˆ Whisper APIã€è¦å‰‡åŒ¹é…ç³»çµ±å’Œ TTS èªéŸ³å›è¦†

åŠŸèƒ½ç‰¹è‰²ï¼š
1. Whisper API é«˜æº–ç¢ºåº¦èªéŸ³è­˜åˆ¥
2. YAML è¦å‰‡åŒ¹é…ç³»çµ±
3. OpenAI TTS èªéŸ³å›è¦†
4. é è¼‰å…¥å¿«å–å„ªåŒ–
5. èˆ‡ç™¼çƒæ©Ÿæ§åˆ¶ç³»çµ±æ•´åˆ
"""

import asyncio
import json
import os
import sys
import time
import logging
import threading
import re
from typing import Optional, Dict, List, Any
from dataclasses import dataclass, field
from pathlib import Path

import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as wavwrite
from openai import OpenAI

try:
    # ç¹é«”è½‰æ›
    from opencc import OpenCC
    _cc = OpenCC('s2twp')
except ImportError:
    _cc = None

try:
    # èªé€Ÿèª¿æ•´
    from pydub import AudioSegment
    from pydub.effects import speedup
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

try:
    import webrtcvad
    WEBRTCVAD_AVAILABLE = True
except ImportError:
    WEBRTCVAD_AVAILABLE = False

try:
    # è¦å‰‡ç³»çµ±
    import yaml
    from rapidfuzz import fuzz
    RULES_AVAILABLE = True
except ImportError:
    RULES_AVAILABLE = False


@dataclass
class AudioConfig:
    """éŸ³è¨Šé…ç½®"""
    sample_rate: int = 16000
    channels: int = 1
    frame_duration_ms: int = 30
    min_speech_frames: int = 10
    max_recording_ms: int = 60000
    silence_ms: int = 500
    aggressiveness: int = 2


@dataclass
class PreloadConfig:
    """é è¼‰å…¥é…ç½®"""
    enabled: bool = True  # å•Ÿç”¨é è¼‰å…¥
    max_cache_size: int = 50  # æœ€å¤§å¿«å–æ•¸é‡
    preload_common_replies: bool = True  # é è¼‰å…¥å¸¸ç”¨å›è¦†
    prediction_enabled: bool = True  # å•Ÿç”¨é æ¸¬é‚è¼¯
    cache_ttl: int = 3600  # å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
    hot_reload_threshold: int = 3  # ç†±é»é‡æ–°è¼‰å…¥é–¾å€¼
    # æŒä¹…åŒ–å¿«å–é…ç½®
    persistent_cache: bool = True  # å•Ÿç”¨æŒä¹…åŒ–å¿«å–
    cache_file: str = "cache/reply_cache.json"  # å¿«å–æª”æ¡ˆè·¯å¾‘
    auto_save_interval: int = 300  # è‡ªå‹•å„²å­˜é–“éš”ï¼ˆç§’ï¼‰
    # è¦å‰‡å¿«å–é…ç½®
    rule_cache_enabled: bool = True  # å•Ÿç”¨è¦å‰‡å¿«å–
    rule_cache_ttl: int = 300  # è¦å‰‡å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
    preload_rules: bool = True  # é è¼‰å…¥è¦å‰‡åŒ¹é…

@dataclass
class VoiceConfig:
    """èªéŸ³é…ç½®"""
    audio: AudioConfig = field(default_factory=AudioConfig)
    default_voice: str = "nova"
    default_speed: float = 1.2
    whisper_model: str = "whisper-1"
    whisper_language: str = "zh"
    rules_path: str = "rules/badminton_rules.yaml"
    enable_tts: bool = True
    enable_rules: bool = True
    safe_mode: bool = True  # å®‰å…¨æ¨¡å¼ï¼Œæ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨å’ŒéŒ¯èª¤è™•ç†
    # é è¼‰å…¥é…ç½®
    preload: PreloadConfig = field(default_factory=PreloadConfig)


# å…¨åŸŸé…ç½®
voice_config = VoiceConfig()

# è¦å‰‡å¿«å–
_RULES_CACHE = {"path": None, "mtime": 0.0, "data": None}

# === é è¼‰å…¥å›è¦†æ¨¡æ¿ç³»çµ± ===
class ReplyTemplateCache:
    """å›è¦†æ¨¡æ¿å¿«å–ç³»çµ±ï¼ˆæ”¯æ´æŒä¹…åŒ–ï¼‰"""
    
    def __init__(self, config: PreloadConfig):
        self.config = config
        self.cache = {}  # {query_hash: {"reply": str, "timestamp": float, "count": int}}
        self.common_templates = {}  # å¸¸ç”¨å›è¦†æ¨¡æ¿
        self.prediction_queue = []  # é æ¸¬ä½‡åˆ—
        self.last_save_time = time.time()  # ä¸Šæ¬¡å„²å­˜æ™‚é–“
        self.rule_cache = {}  # è¦å‰‡åŒ¹é…çµæœå¿«å–
        self._load_common_templates()
        self._load_persistent_cache()
    
    def _load_common_templates(self):
        """è¼‰å…¥å¸¸ç”¨å›è¦†æ¨¡æ¿"""
        self.common_templates = {
            # ç¾½çƒç›¸é—œå¸¸ç”¨å›è¦†
            "é–‹å§‹": ["å¥½çš„ï¼Œæˆ‘å€‘é–‹å§‹ç·´ç¿’å§ï¼", "æº–å‚™å¥½äº†å—ï¼Ÿé–‹å§‹ç™¼çƒï¼", "é–‹å§‹è¨“ç·´ï¼"],
            "åœæ­¢": ["å¥½çš„ï¼Œåœæ­¢ç™¼çƒã€‚", "è¨“ç·´çµæŸï¼", "åœæ­¢ç™¼çƒæ©Ÿã€‚"],
            "é€Ÿåº¦": ["èª¿æ•´ç™¼çƒé€Ÿåº¦", "é€Ÿåº¦è¨­å®šå®Œæˆ", "ç™¼çƒé€Ÿåº¦å·²èª¿æ•´"],
            "è§’åº¦": ["èª¿æ•´ç™¼çƒè§’åº¦", "è§’åº¦è¨­å®šå®Œæˆ", "ç™¼çƒè§’åº¦å·²èª¿æ•´"],
            "çƒæ•¸": ["å‰©é¤˜çƒæ•¸", "çƒæ•¸çµ±è¨ˆ", "ç™¼çƒæ•¸é‡"],
            "å¹«åŠ©": ["æˆ‘å¯ä»¥å¹«ä½ æ§åˆ¶ç™¼çƒæ©Ÿ", "éœ€è¦ä»€éº¼å¹«åŠ©å—ï¼Ÿ", "æœ‰ä»€éº¼å•é¡Œå—ï¼Ÿ"],
            "è¬è¬": ["ä¸å®¢æ°£ï¼", "å¾ˆé«˜èˆˆèƒ½å¹«åŠ©ä½ ", "éš¨æ™‚ç‚ºä½ æœå‹™"],
            "ä½ å¥½": ["ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ç¾½çƒç™¼çƒæ©ŸåŠ©ç†", "å—¨ï¼æº–å‚™é–‹å§‹è¨“ç·´å—ï¼Ÿ", "ä½ å¥½ï¼ä»Šå¤©æƒ³ç·´ä»€éº¼ï¼Ÿ"],
            
            # é€šç”¨å›è¦†
            "ä¸çŸ¥é“": ["æˆ‘ä¸å¤ªç¢ºå®šï¼Œè®“æˆ‘å†æƒ³æƒ³", "é€™å€‹å•é¡Œæœ‰é»é›£ï¼Œè®“æˆ‘æŸ¥ä¸€ä¸‹", "æˆ‘éœ€è¦æ›´å¤šè³‡è¨Š"],
            "é‡è¤‡": ["è«‹å†èªªä¸€é", "æˆ‘æ²’è½æ¸…æ¥š", "å¯ä»¥é‡è¤‡ä¸€æ¬¡å—ï¼Ÿ"],
            "ç¢ºèª": ["å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†", "æ”¶åˆ°ï¼", "ç¢ºèªå®Œæˆ"],
            "å–æ¶ˆ": ["å·²å–æ¶ˆ", "æ“ä½œå–æ¶ˆ", "å–æ¶ˆå®Œæˆ"],
        }
    
    def cache_rule_result(self, query: str, rule_result: dict):
        """å¿«å–è¦å‰‡åŒ¹é…çµæœ"""
        if not (self.config.enabled and self.config.rule_cache_enabled):
            return
        
        query_hash = self._hash_query(query)
        self.rule_cache[query_hash] = {
            "rule": rule_result,
            "timestamp": time.time(),
            "count": 1
        }
    
    def get_cached_rule_result(self, query: str) -> Optional[dict]:
        """ç²å–å¿«å–çš„è¦å‰‡åŒ¹é…çµæœ"""
        if not (self.config.enabled and self.config.rule_cache_enabled):
            return None
        
        query_hash = self._hash_query(query)
        if query_hash in self.rule_cache:
            cached = self.rule_cache[query_hash]
            # æª¢æŸ¥å¿«å–æ˜¯å¦éæœŸ
            if time.time() - cached["timestamp"] < self.config.rule_cache_ttl:
                cached["count"] += 1
                return cached["rule"]
            else:
                # éæœŸå‰‡ç§»é™¤
                del self.rule_cache[query_hash]
        
        return None
    
    def _hash_query(self, query: str) -> str:
        """ç”ŸæˆæŸ¥è©¢çš„é›œæ¹Šå€¼"""
        import hashlib
        normalized = _normalize_zh(query)
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def get_cached_reply(self, query: str) -> Optional[str]:
        """ç²å–å¿«å–çš„å›è¦†"""
        if not self.config.enabled:
            return None
        
        query_hash = self._hash_query(query)
        if query_hash in self.cache:
            cached = self.cache[query_hash]
            # æª¢æŸ¥å¿«å–æ˜¯å¦éæœŸ
            if time.time() - cached["timestamp"] < self.config.cache_ttl:
                cached["count"] += 1
                return cached["reply"]
            else:
                # éæœŸå‰‡ç§»é™¤
                del self.cache[query_hash]
        
        return None
    
    def _cleanup_cache(self):
        """æ¸…ç†å¿«å–ï¼ˆç§»é™¤æœ€å°‘ä½¿ç”¨çš„é …ç›®ï¼‰"""
        if not self.cache:
            return
        
        # æŒ‰ä½¿ç”¨æ¬¡æ•¸æ’åºï¼Œç§»é™¤æœ€å°‘ä½¿ç”¨çš„
        sorted_items = sorted(self.cache.items(), key=lambda x: x[1]["count"])
        # ç§»é™¤æœ€èˆŠçš„ 25%
        remove_count = max(1, len(sorted_items) // 4)
        for key, _ in sorted_items[:remove_count]:
            del self.cache[key]
    
    def predict_and_preload(self, current_query: str, conversation_history: list):
        """é æ¸¬å¯èƒ½çš„å¾ŒçºŒå•é¡Œä¸¦é è¼‰å…¥"""
        if not self.config.prediction_enabled:
            return
        
        # åŸºæ–¼ç•¶å‰æŸ¥è©¢å’Œå°è©±æ­·å²é æ¸¬å¯èƒ½çš„å¾ŒçºŒå•é¡Œ
        predictions = self._generate_predictions(current_query, conversation_history)
        
        # å°‡é æ¸¬åŠ å…¥ä½‡åˆ—
        for prediction in predictions:
            if prediction not in self.prediction_queue:
                self.prediction_queue.append(prediction)
    
    def _generate_predictions(self, current_query: str, conversation_history: list) -> list:
        """ç”Ÿæˆé æ¸¬æŸ¥è©¢ï¼ˆåŸºæ–¼è¦å‰‡ç³»çµ±ï¼‰"""
        predictions = []
        
        # åŸºæ–¼é—œéµè©é æ¸¬
        query_lower = current_query.lower()
        
        # ç¾½çƒè¨“ç·´ç›¸é—œé æ¸¬
        if "é–‹å§‹" in query_lower or "start" in query_lower:
            predictions.extend(["åœæ­¢", "å¿«é€Ÿ", "æ…¢é€Ÿ", "å‰å ´", "å¾Œå ´", "æ®ºçƒ"])
        elif "åœæ­¢" in query_lower or "stop" in query_lower:
            predictions.extend(["é–‹å§‹", "ç‹€æ…‹", "çƒæ•¸"])
        elif "é€Ÿåº¦" in query_lower or "speed" in query_lower or "å¿«" in query_lower or "æ…¢" in query_lower:
            predictions.extend(["è§’åº¦", "é–‹å§‹", "åœæ­¢", "å·¦é‚Š", "å³é‚Š"])
        elif "è§’åº¦" in query_lower or "angle" in query_lower or "å·¦" in query_lower or "å³" in query_lower:
            predictions.extend(["é€Ÿåº¦", "é–‹å§‹", "åœæ­¢", "æé«˜", "é™ä½"])
        elif "çƒæ•¸" in query_lower or "ball" in query_lower or "å‰©é¤˜" in query_lower:
            predictions.extend(["é–‹å§‹", "åœæ­¢", "ç‹€æ…‹"])
        elif "å‰å ´" in query_lower or "ç¶²å‰" in query_lower:
            predictions.extend(["å¾Œå ´", "æ®ºçƒ", "åŠçƒ", "åœæ­¢"])
        elif "å¾Œå ´" in query_lower or "åº•ç·š" in query_lower:
            predictions.extend(["å‰å ´", "æ®ºçƒ", "åŠçƒ", "åœæ­¢"])
        elif "æ®ºçƒ" in query_lower or "æ‰£æ®º" in query_lower:
            predictions.extend(["åŠçƒ", "å‰å ´", "å¾Œå ´", "åœæ­¢"])
        elif "åŠçƒ" in query_lower or "è¼•åŠ" in query_lower:
            predictions.extend(["æ®ºçƒ", "å‰å ´", "å¾Œå ´", "åœæ­¢"])
        
        # åŸºæ–¼å°è©±æ­·å²é æ¸¬
        if conversation_history:
            last_reply = conversation_history[-1].get("content", "").lower()
            if "é–‹å§‹" in last_reply:
                predictions.extend(["åœæ­¢", "å¿«é€Ÿ", "æ…¢é€Ÿ", "å‰å ´", "å¾Œå ´"])
            elif "é€Ÿåº¦" in last_reply or "å¿«" in last_reply or "æ…¢" in last_reply:
                predictions.extend(["è§’åº¦", "é–‹å§‹", "å·¦é‚Š", "å³é‚Š"])
            elif "è§’åº¦" in last_reply or "å·¦" in last_reply or "å³" in last_reply:
                predictions.extend(["é€Ÿåº¦", "é–‹å§‹", "æé«˜", "é™ä½"])
        
        return predictions[:8]  # å¢åŠ é æ¸¬æ•¸é‡
    
    def get_common_reply(self, query: str) -> Optional[str]:
        """ç²å–å¸¸ç”¨å›è¦†æ¨¡æ¿"""
        query_lower = _normalize_zh(query)
        
        # ç›´æ¥åŒ¹é…
        for key, replies in self.common_templates.items():
            if key in query_lower:
                import random
                return random.choice(replies)
        
        # æ¨¡ç³ŠåŒ¹é…
        for key, replies in self.common_templates.items():
            if fuzz.partial_ratio(query_lower, key) >= 80:
                import random
                return random.choice(replies)
        
        return None
    
    def _load_persistent_cache(self):
        """è¼‰å…¥æŒä¹…åŒ–å¿«å–"""
        if not self.config.persistent_cache:
            return
        
        cache_file = self.config.cache_file
        try:
            # ç¢ºä¿å¿«å–ç›®éŒ„å­˜åœ¨
            cache_dir = os.path.dirname(cache_file)
            if cache_dir and not os.path.exists(cache_dir):
                os.makedirs(cache_dir, exist_ok=True)
            
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # è¼‰å…¥å¿«å–è³‡æ–™
                for query_hash, cache_data in data.get("cache", {}).items():
                    # æª¢æŸ¥å¿«å–æ˜¯å¦éæœŸ
                    if time.time() - cache_data["timestamp"] < self.config.cache_ttl:
                        self.cache[query_hash] = cache_data
                
                print(f"ğŸ“‚ è¼‰å…¥æŒä¹…åŒ–å¿«å–ï¼š{len(self.cache)} å€‹é …ç›®")
            else:
                print("ğŸ“‚ æœªæ‰¾åˆ°å¿«å–æª”æ¡ˆï¼Œå°‡å»ºç«‹æ–°çš„å¿«å–")
                
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥å¿«å–å¤±æ•—ï¼š{e}")
    
    def _save_persistent_cache(self):
        """å„²å­˜æŒä¹…åŒ–å¿«å–"""
        if not self.config.persistent_cache:
            return
        
        cache_file = self.config.cache_file
        try:
            # ç¢ºä¿å¿«å–ç›®éŒ„å­˜åœ¨
            cache_dir = os.path.dirname(cache_file)
            if cache_dir and not os.path.exists(cache_dir):
                os.makedirs(cache_dir, exist_ok=True)
            
            # æº–å‚™å„²å­˜è³‡æ–™
            data = {
                "cache": self.cache,
                "metadata": {
                    "saved_at": time.time(),
                    "version": "1.0",
                    "total_items": len(self.cache)
                }
            }
            
            # å„²å­˜åˆ°æª”æ¡ˆ
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.last_save_time = time.time()
            print(f"ğŸ’¾ å¿«å–å·²å„²å­˜ï¼š{len(self.cache)} å€‹é …ç›®")
            
        except Exception as e:
            print(f"âš ï¸ å„²å­˜å¿«å–å¤±æ•—ï¼š{e}")
    
    def _should_auto_save(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²è‡ªå‹•å„²å­˜"""
        return (time.time() - self.last_save_time) >= self.config.auto_save_interval
    
    def cache_reply(self, query: str, reply: str):
        """å¿«å–å›è¦†ï¼ˆæ”¯æ´è‡ªå‹•å„²å­˜ï¼‰"""
        if not self.config.enabled:
            return
        
        query_hash = self._hash_query(query)
        
        # æª¢æŸ¥å¿«å–å¤§å°é™åˆ¶
        if len(self.cache) >= self.config.max_cache_size:
            self._cleanup_cache()
        
        self.cache[query_hash] = {
            "reply": reply,
            "timestamp": time.time(),
            "count": 1
        }
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦è‡ªå‹•å„²å­˜
        if self._should_auto_save():
            self._save_persistent_cache()
    
    def get_cache_stats(self) -> dict:
        """ç²å–å¿«å–çµ±è¨ˆè³‡è¨Š"""
        return {
            "cache_size": len(self.cache),
            "rule_cache_size": len(self.rule_cache),
            "common_templates": len(self.common_templates),
            "prediction_queue": len(self.prediction_queue),
            "total_queries": sum(item["count"] for item in self.cache.values()),
            "total_rule_hits": sum(item["count"] for item in self.rule_cache.values()),
            "persistent_cache": self.config.persistent_cache,
            "cache_file": self.config.cache_file,
            "last_save": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(self.last_save_time))
        }
    
    def save_cache_now(self):
        """ç«‹å³å„²å­˜å¿«å–"""
        self._save_persistent_cache()
    
    def clear_cache(self):
        """æ¸…ç©ºå¿«å–"""
        self.cache.clear()
        self.rule_cache.clear()
        if self.config.persistent_cache:
            self._save_persistent_cache()
        print("ğŸ—‘ï¸ å¿«å–å·²æ¸…ç©º")

# === é è¼‰å…¥ç®¡ç†å™¨ ===
class PreloadManager:
    """é è¼‰å…¥ç®¡ç†å™¨"""
    
    def __init__(self, client: OpenAI, reply_cache: ReplyTemplateCache):
        self.client = client
        self.reply_cache = reply_cache
        self.preload_thread = None
        self.is_running = False
        self.preload_queue = []
    
    def start_background_preload(self):
        """å•Ÿå‹•èƒŒæ™¯é è¼‰å…¥åŸ·è¡Œç·’"""
        if not self.reply_cache.config.enabled:
            return
        
        self.is_running = True
        self.preload_thread = threading.Thread(target=self._background_preload_worker, daemon=True)
        self.preload_thread.start()
        print("ğŸ”„ èƒŒæ™¯é è¼‰å…¥åŸ·è¡Œç·’å·²å•Ÿå‹•")
    
    def stop_background_preload(self):
        """åœæ­¢èƒŒæ™¯é è¼‰å…¥åŸ·è¡Œç·’"""
        self.is_running = False
        if self.preload_thread:
            self.preload_thread.join(timeout=1)
        print("â¹ï¸ èƒŒæ™¯é è¼‰å…¥åŸ·è¡Œç·’å·²åœæ­¢")
    
    def _background_preload_worker(self):
        """èƒŒæ™¯é è¼‰å…¥å·¥ä½œåŸ·è¡Œç·’"""
        while self.is_running:
            try:
                # è™•ç†é è¼‰å…¥ä½‡åˆ—
                if self.reply_cache.prediction_queue:
                    prediction = self.reply_cache.prediction_queue.pop(0)
                    self._preload_reply(prediction)
                
                # è™•ç†é è¼‰å…¥ä½‡åˆ—
                if self.preload_queue:
                    query = self.preload_queue.pop(0)
                    self._preload_reply(query)
                
                time.sleep(0.1)  # çŸ­æš«ä¼‘æ¯
                
            except Exception as e:
                print(f"âš ï¸ é è¼‰å…¥åŸ·è¡Œç·’éŒ¯èª¤ï¼š{e}")
                time.sleep(1)
    
    def _preload_reply(self, query: str):
        """é è¼‰å…¥å›è¦†"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“å¿«å–
            if self.reply_cache.get_cached_reply(query):
                return
            
            # é¦–å…ˆæª¢æŸ¥è¦å‰‡åŒ¹é…
            rule_result = self._preload_rule_match(query)
            if rule_result:
                return
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å¸¸ç”¨å›è¦†æ¨¡æ¿
            common_reply = self.reply_cache.get_common_reply(query)
            if common_reply:
                self.reply_cache.cache_reply(query, common_reply)
                return
            
            # ä½¿ç”¨ LLM ç”Ÿæˆå›è¦†ï¼ˆä½å„ªå…ˆç´šï¼‰
            if len(self.reply_cache.cache) < self.reply_cache.config.max_cache_size // 2:
                reply = self._generate_preload_reply(query)
                if reply:
                    self.reply_cache.cache_reply(query, reply)
        
        except Exception as e:
            print(f"âš ï¸ é è¼‰å…¥å›è¦†å¤±æ•—ï¼š{e}")
    
    def _preload_rule_match(self, query: str) -> bool:
        """é è¼‰å…¥è¦å‰‡åŒ¹é…çµæœ"""
        if not self.reply_cache.config.preload_rules:
            return False
            
        try:
            # ä½¿ç”¨é è¨­è¦å‰‡æª”æ¡ˆé€²è¡ŒåŒ¹é…
            default_rules_path = "rules/badminton_rules.yaml"
            if os.path.exists(default_rules_path):
                matcher = RuleMatcher(default_rules_path)
                hit = matcher.match(query)
                if hit:
                    # å¿«å–è¦å‰‡åŒ¹é…çµæœ
                    self.reply_cache.cache_rule_result(query, hit)
                    
                    # ç”Ÿæˆä¸¦å¿«å–å›è¦†
                    context = {"balls_left": 48}
                    reply_text = format_reply(hit.get("reply", {}).get("text", ""), context)
                    self.reply_cache.cache_reply(query, reply_text)
                    return True
        except Exception as e:
            print(f"âš ï¸ é è¼‰å…¥è¦å‰‡åŒ¹é…å¤±æ•—ï¼š{e}")
        
        return False
    
    def _generate_preload_reply(self, query: str) -> Optional[str]:
        """ç”Ÿæˆé è¼‰å…¥å›è¦†"""
        try:
            # ä½¿ç”¨ç°¡æ½”çš„ç³»çµ±æç¤º
            system_prompt = "ä½ æ˜¯ç¾½çƒç™¼çƒæ©ŸåŠ©ç†ï¼Œè«‹ç”¨ç°¡æ½”çš„1-2å¥è©±å›è¦†ã€‚"
            
            # ç°¡åŒ–çš„ LLM å›è¦†ç”Ÿæˆ
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.3,
                max_tokens=50
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆé è¼‰å…¥å›è¦†å¤±æ•—ï¼š{e}")
            return None
    
    def add_to_preload_queue(self, query: str):
        """æ·»åŠ æŸ¥è©¢åˆ°é è¼‰å…¥ä½‡åˆ—"""
        if query not in self.preload_queue:
            self.preload_queue.append(query)
    
    def preload_common_queries(self):
        """é è¼‰å…¥å¸¸ç”¨æŸ¥è©¢ï¼ˆåŸºæ–¼è¦å‰‡ç³»çµ±ï¼‰"""
        common_queries = [
            # åŸºæœ¬æ§åˆ¶
            "é–‹å§‹ç™¼çƒ", "åœæ­¢ç™¼çƒ", "é–‹å§‹è¨“ç·´", "åœæ­¢è¨“ç·´",
            # é€Ÿåº¦æ§åˆ¶
            "å¿«é€Ÿ", "æ…¢é€Ÿ", "ä¸­é€Ÿ", "åŠ é€Ÿ", "æ¸›é€Ÿ",
            # è§’åº¦æ§åˆ¶
            "å·¦é‚Š", "å³é‚Š", "ä¸­é–“", "å·¦è½‰", "å³è½‰",
            # é«˜åº¦æ§åˆ¶
            "æé«˜", "é™ä½", "ä¸Šå‡", "ä¸‹é™",
            # è¨“ç·´æ¨¡å¼
            "å‰å ´ç·´ç¿’", "å¾Œå ´ç·´ç¿’", "æ®ºçƒç·´ç¿’", "åŠçƒç·´ç¿’",
            "æ­£æ‰‹ç·´ç¿’", "åæ‰‹ç·´ç¿’", "ç›´ç·šçƒ", "æ–œç·šçƒ",
            # ç‹€æ…‹æŸ¥è©¢
            "å‰©é¤˜çƒæ•¸", "ç¾åœ¨ç‹€æ…‹", "é€²åº¦å¦‚ä½•", "å ±å‘Šç‹€æ…‹",
            # åŸºæœ¬äº’å‹•
            "å¹«åŠ©", "è¬è¬", "ä½ å¥½", "å†è¦‹", "è¾›è‹¦äº†"
        ]
        
        for query in common_queries:
            self.add_to_preload_queue(query)
        
        print(f"ğŸ“‹ å·²æ’ç¨‹ {len(common_queries)} å€‹å¸¸ç”¨æŸ¥è©¢é è¼‰å…¥")

# === æ¨¡å¼ç®¡ç†ç³»çµ± ===
class ModeManager:
    """æ¨¡å¼ç®¡ç†å™¨ï¼šè™•ç†æ§åˆ¶æ¨¡å¼å’Œæ€è€ƒæ¨¡å¼çš„åˆ‡æ›"""
    
    def __init__(self, default_mode: str = "control", think_on: str = "å•Ÿå‹•æ€è€ƒæ¨¡å¼", 
                 control_on: str = "å•Ÿå‹•æ§åˆ¶æ¨¡å¼", mismatch_reply: str = "æˆ‘ç¾åœ¨åœ¨æ§åˆ¶æ¨¡å¼ï¼Œè«‹ç”¨æ˜ç¢ºçš„æŒ‡ä»¤å†èªªä¸€æ¬¡ã€‚"):
        self.current_mode = default_mode  # "control" æˆ– "think"
        self.think_on_keyword = think_on
        self.control_on_keyword = control_on
        self.mismatch_reply = mismatch_reply
        self.mode_history = []  # è¨˜éŒ„æ¨¡å¼åˆ‡æ›æ­·å²
        
    def get_current_mode(self) -> str:
        """ç²å–ç•¶å‰æ¨¡å¼"""
        return self.current_mode
    
    def is_control_mode(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæ§åˆ¶æ¨¡å¼"""
        return self.current_mode == "control"
    
    def is_think_mode(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæ€è€ƒæ¨¡å¼"""
        return self.current_mode == "think"
    
    def check_mode_switch(self, text: str) -> Optional[str]:
        """æª¢æŸ¥æ˜¯å¦è§¸ç™¼æ¨¡å¼åˆ‡æ›ï¼Œè¿”å›åˆ‡æ›å¾Œçš„å›è¦†æˆ– None"""
        normalized_text = _normalize_zh(text)
        think_keyword = _normalize_zh(self.think_on_keyword)
        control_keyword = _normalize_zh(self.control_on_keyword)
        
        # æª¢æŸ¥æ˜¯å¦è¦åˆ‡æ›åˆ°æ€è€ƒæ¨¡å¼
        if think_keyword in normalized_text and self.current_mode == "control":
            self._switch_to_think()
            return f"å·²åˆ‡æ›åˆ°æ€è€ƒæ¨¡å¼ï¼Œç¾åœ¨å¯ä»¥ä½¿ç”¨ LLM é€²è¡Œå°è©±ã€‚"
        
        # æª¢æŸ¥æ˜¯å¦è¦åˆ‡æ›åˆ°æ§åˆ¶æ¨¡å¼
        if control_keyword in normalized_text and self.current_mode == "think":
            self._switch_to_control()
            return f"å·²åˆ‡æ›åˆ°æ§åˆ¶æ¨¡å¼ï¼Œåªä½¿ç”¨è¦å‰‡åŒ¹é…ï¼Œä¸ä½¿ç”¨ LLMã€‚"
        
        return None
    
    def _switch_to_think(self):
        """åˆ‡æ›åˆ°æ€è€ƒæ¨¡å¼"""
        old_mode = self.current_mode
        self.current_mode = "think"
        self.mode_history.append({
            "from": old_mode,
            "to": "think",
            "timestamp": time.time()
        })
        print(f"ğŸ”„ æ¨¡å¼åˆ‡æ›ï¼š{old_mode} â†’ think")
    
    def _switch_to_control(self):
        """åˆ‡æ›åˆ°æ§åˆ¶æ¨¡å¼"""
        old_mode = self.current_mode
        self.current_mode = "control"
        self.mode_history.append({
            "from": old_mode,
            "to": "control",
            "timestamp": time.time()
        })
        print(f"ğŸ”„ æ¨¡å¼åˆ‡æ›ï¼š{old_mode} â†’ control")
    
    def get_mismatch_reply(self) -> str:
        """ç²å–æ§åˆ¶æ¨¡å¼ä¸‹è¦å‰‡ä¸åŒ¹é…æ™‚çš„å›è¦†"""
        return self.mismatch_reply
    
    def get_mode_status(self) -> dict:
        """ç²å–æ¨¡å¼ç‹€æ…‹è³‡è¨Š"""
        return {
            "current_mode": self.current_mode,
            "think_keyword": self.think_on_keyword,
            "control_keyword": self.control_on_keyword,
            "switch_count": len(self.mode_history),
            "last_switch": self.mode_history[-1] if self.mode_history else None
        }

# === é€²åº¦æŒ‡ç¤ºå™¨ç³»çµ± ===
def show_progress(message: str, duration: float = 0.5, show_dots: bool = True):
    """é¡¯ç¤ºé€²åº¦æŒ‡ç¤º"""
    print(f"â³ {message}", end="", flush=True)
    if show_dots:
        time.sleep(duration)
        print(" âœ…")
    else:
        print()

def show_fast_progress(message: str):
    """å¿«é€Ÿé€²åº¦æŒ‡ç¤ºï¼ˆç„¡å»¶é²ï¼‰"""
    print(f"âš¡ {message}")

def show_progress_with_dots(message: str, total_steps: int = 3):
    """é¡¯ç¤ºå¸¶é»é»çš„é€²åº¦æŒ‡ç¤º"""
    print(f"â³ {message}", end="", flush=True)
    for i in range(total_steps):
        time.sleep(0.3)
        print(".", end="", flush=True)
    print(" âœ…")

def show_loading_bar(message: str, duration: float = 2.0, width: int = 20):
    """é¡¯ç¤ºè¼‰å…¥é€²åº¦æ¢"""
    print(f"â³ {message}")
    for i in range(width + 1):
        progress = i / width
        bar = "â–ˆ" * i + "â–‘" * (width - i)
        print(f"\r[{bar}] {progress*100:.0f}%", end="", flush=True)
        time.sleep(duration / width)
    print()  # æ›è¡Œ

# === è¨˜æ†¶é«”å„ªåŒ– ===
def _optimize_audio_buffer(audio_buffer: list, max_frames: Optional[int] = None) -> list:
    """å„ªåŒ–éŸ³è¨Šç·©è¡å€è¨˜æ†¶é«”ä½¿ç”¨"""
    if max_frames is None:
        max_frames = 1000  # é è¨­æœ€å¤§ç·©è¡å€å¹€æ•¸
    
    if len(audio_buffer) > max_frames:
        # åªä¿ç•™æœ€è¿‘çš„éŸ³è¨Šå¹€ï¼Œé‡‹æ”¾èˆŠçš„è¨˜æ†¶é«”
        return audio_buffer[-max_frames:]
    return audio_buffer

def _cleanup_old_frames(audio_buffer: list, threshold: Optional[int] = None) -> list:
    """æ¸…ç†èˆŠçš„éŸ³è¨Šå¹€ä»¥é‡‹æ”¾è¨˜æ†¶é«”"""
    if threshold is None:
        threshold = 500  # é è¨­ç·©è¡å€æ¸…ç†é–¾å€¼
    
    if len(audio_buffer) > threshold:
        # ä¿ç•™æœ€è¿‘çš„å¹€ï¼Œæ¸…ç†èˆŠçš„
        return audio_buffer[-threshold:]
    return audio_buffer

def _get_memory_usage() -> float:
    """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
    try:
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024  # è½‰æ›ç‚º MB
    except ImportError:
        return 0.0

def _log_memory_usage(operation: str):
    """è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ï¼ˆå·²åœç”¨ï¼‰"""
    pass  # ä¸å†è¼¸å‡ºè¨˜æ†¶é«”è³‡è¨Š

# ä¸­æ–‡æ¨™é»ç¬¦è™Ÿ
_ZH_PUNCT = "ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€ã€ã€ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€”ï¼â€¦â€§,.!?;:()[]{}<>~`@#$%^&*-_=+|/\\\"'\u3000 "


def _normalize_zh(s: str) -> str:
    """æ­£è¦åŒ–ä¸­æ–‡æ–‡æœ¬"""
    s = (s or "").strip().lower()
    for ch in _ZH_PUNCT:
        s = s.replace(ch, "")
    return s


def s2twp(text: str, enabled: bool = True) -> str:
    """ç°¡é«”è½‰ç¹é«”"""
    if not enabled or not text:
        return text
    if _cc is None:
        return text
    return _cc.convert(text)


class RuleMatcher:
    """è¦å‰‡åŒ¹é…å™¨"""
    
    def __init__(self, rules_path: str):
        self.rules_path = rules_path
        self._rules_data = None
        self._last_mtime = 0.0
    
    def _load_rules(self) -> dict:
        """è¼‰å…¥è¦å‰‡æª”æ¡ˆ"""
        global _RULES_CACHE
        p = os.path.abspath(self.rules_path)
        
        if not os.path.exists(p):
            print(f"âš ï¸ è¦å‰‡æª”æ¡ˆä¸å­˜åœ¨ï¼š{p}")
            return {"rules": []}
        
        mtime = os.path.getmtime(p)
        
        # æª¢æŸ¥å¿«å–
        if (_RULES_CACHE["path"] == p and 
            _RULES_CACHE["mtime"] == mtime and 
            _RULES_CACHE["data"] is not None):
            return _RULES_CACHE["data"]
        
        try:
            with open(p, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f) or {}
            
            # é è™•ç†è¦å‰‡
            for r in data.get("rules", []):
                r.setdefault("priority", 0)
                r.setdefault("match", {})
                r["match"].setdefault("contains", [])
                r["match"].setdefault("regex", [])
                r["match"].setdefault("fuzzy", [])
                
                # é å»ºæ­£è¦åŒ–å­—ä¸²
                r["_contains_norm"] = [_normalize_zh(x) for x in r["match"]["contains"]]
            
            # æ›´æ–°å¿«å–
            _RULES_CACHE = {"path": p, "mtime": mtime, "data": data}
            return data
            
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥è¦å‰‡æª”æ¡ˆå¤±æ•—ï¼š{e}")
            return {"rules": []}
    
    def match(self, text: str) -> Optional[dict]:
        """åŒ¹é…è¦å‰‡"""
        if not text.strip():
            return None
        
        rules_data = self._load_rules()
        ntext = _normalize_zh(text)
        rules = sorted(rules_data.get("rules", []), 
                      key=lambda r: r.get("priority", 0), reverse=True)
        fuzzy_th = rules_data.get("globals", {}).get("fuzzy_threshold", 86)

        for r in rules:
            # åŒ…å«å¼åŒ¹é…
            for key_norm in r.get("_contains_norm", []):
                if key_norm and key_norm in ntext:
                    return r
            
            # æ­£å‰‡åŒ¹é…
            for pat in r["match"].get("regex", []):
                try:
                    if re.search(pat, text):
                        return r
                except re.error:
                    continue
            
            # æ¨¡ç³ŠåŒ¹é…
            for k in r["match"].get("fuzzy", []):
                if fuzz.partial_ratio(ntext, _normalize_zh(k)) >= fuzzy_th:
                    return r
        
        return None


class VoiceControlTTS:
    """
    èªéŸ³æ§åˆ¶ç³»çµ± - TTS æ•´åˆç‰ˆ
    æ”¯æ´ Whisper API èªéŸ³è­˜åˆ¥ã€è¦å‰‡åŒ¹é…å’Œ TTS å›è¦†
    """
    
    def __init__(self, window, config: Optional[VoiceConfig] = None):
        self.window = window
        self.config = config or voice_config
        
        # OpenAI å®¢æˆ¶ç«¯
        self.client = None
        self._init_openai_client()
        
        # éŸ³è¨Šç›¸é—œ
        self._audio_stream = None
        self._running = False
        self._starting = False
        self._audio_queue: asyncio.Queue = asyncio.Queue()
        self._listen_task: Optional[asyncio.Task] = None
        self._capture_task: Optional[asyncio.Task] = None
        self._start_stop_lock = asyncio.Lock()
        
        # è¦å‰‡åŒ¹é…å™¨
        self.rule_matcher = None
        if self.config.enable_rules and RULES_AVAILABLE:
            self.rule_matcher = RuleMatcher(self.config.rules_path)
        
        # éŸ³è¨Šç·©å­˜
        self._audio_buffer = []
        self._vad = None
        
        # è¨­å‚™é…ç½®
        self.input_device = None
        
        # é è¼‰å…¥ç³»çµ±
        self.reply_cache = None
        self.preload_manager = None
        if self.config.preload.enabled:
            self.reply_cache = ReplyTemplateCache(self.config.preload)
            if self.client:
                self.preload_manager = PreloadManager(self.client, self.reply_cache)
        
        # æ¨¡å¼ç®¡ç†å™¨
        self.mode_manager = ModeManager(
            default_mode="control",
            think_on="å•Ÿå‹•æ€è€ƒæ¨¡å¼",
            control_on="å•Ÿå‹•æ§åˆ¶æ¨¡å¼",
            mismatch_reply="æˆ‘ç¾åœ¨åœ¨æ§åˆ¶æ¨¡å¼ï¼Œè«‹ç”¨æ˜ç¢ºçš„æŒ‡ä»¤å†èªªä¸€æ¬¡ã€‚"
        )
        
        # å°è©±æ­·å²
        self.conversation_history = []
    
    def _init_openai_client(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯"""
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key or api_key == "ä½ çš„key":
            self._log_ui("âŒ è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY")
            return
        
        try:
            self.client = OpenAI(api_key=api_key)
            self._log_ui("âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self._log_ui(f"âŒ OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
    
    def set_input_device(self, device_index: Optional[int]):
        """è¨­å®šè¼¸å…¥è£ç½®"""
        self.input_device = device_index
    
    async def start(self):
        """å•Ÿå‹•èªéŸ³æ§åˆ¶"""
        if self._running or self._starting:
            self._add_chat_message("âš ï¸ èªéŸ³æ§åˆ¶å·²ç¶“åœ¨é‹è¡Œä¸­", "system")
            return
        
        async with self._start_stop_lock:
            if self._running or self._starting:
                self._add_chat_message("âš ï¸ èªéŸ³æ§åˆ¶å·²ç¶“åœ¨é‹è¡Œä¸­", "system")
                return
            self._starting = True
            self._update_status("æ­£åœ¨å•Ÿå‹•èªéŸ³æ§åˆ¶...", "main")
        
        # æª¢æŸ¥ä¾è³´
        if not self._check_dependencies():
            self._starting = False
            return
        
        try:
            # åˆå§‹åŒ– VADï¼ˆå„ªå…ˆä½¿ç”¨ VADï¼Œå®‰å…¨æ¨¡å¼ä½œç‚ºå‚™é¸ï¼‰
            if WEBRTCVAD_AVAILABLE:
                try:
                    self._vad = webrtcvad.Vad(self.config.audio.aggressiveness)
                    self._log_ui("âœ… VAD å·²å•Ÿç”¨")
                except Exception as e:
                    self._log_ui(f"âš ï¸ VAD åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨å›ºå®šæ™‚é•·æ¨¡å¼ï¼š{e}")
                    self._vad = None
            else:
                self._vad = None
                self._log_ui("âš ï¸ webrtcvad æœªå®‰è£ï¼Œä½¿ç”¨å›ºå®šæ™‚é•·éŒ„éŸ³")
                if self.config.safe_mode:
                    self._log_ui("ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼ï¼šä½¿ç”¨å›ºå®šæ™‚é•·éŒ„éŸ³")
            
            # è¨­å®šéŸ³è¨Šæµï¼ˆä¸è¨­ç½® _running ç‹€æ…‹ï¼‰
            await self._setup_audio_stream()
            
            # å•Ÿå‹•é è¼‰å…¥ç³»çµ±
            if self.preload_manager:
                self.preload_manager.start_background_preload()
                self.preload_manager.preload_common_queries()
                self._log_ui("ğŸ“‹ é è¼‰å…¥ç³»çµ±å·²å•Ÿå‹•")
            
            # è¨­ç½®é‹è¡Œç‹€æ…‹
            self._running = True
            
            # å•Ÿå‹•ç›£è½
            self._listen_task = asyncio.create_task(self._listen_loop())
            self._add_chat_message("ğŸ™ï¸ èªéŸ³æ§åˆ¶å·²å•Ÿå‹•ï¼Œè«‹é–‹å§‹èªªè©±...", "system")
            self._add_chat_message(f"ğŸ›ï¸ ç•¶å‰æ¨¡å¼ï¼š{self.mode_manager.get_current_mode()}", "system")
            self._update_status("èªéŸ³æ§åˆ¶é‹è¡Œä¸­", "main")
            self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
            
        except Exception as e:
            self._log_ui(f"âŒ å•Ÿå‹•èªéŸ³æ§åˆ¶å¤±æ•—ï¼š{e}")
            self._running = False
        finally:
            self._starting = False
    
    async def stop(self):
        """åœæ­¢èªéŸ³æ§åˆ¶"""
        async with self._start_stop_lock:
            if not self._running and not self._starting:
                return
            self._starting = False
        
        self._running = False
        self._update_status("æ­£åœ¨åœæ­¢èªéŸ³æ§åˆ¶...", "main")
        
        # åœæ­¢é è¼‰å…¥ç³»çµ±
        if self.preload_manager:
            self.preload_manager.stop_background_preload()
            self._add_chat_message("ğŸ“‹ é è¼‰å…¥ç³»çµ±å·²åœæ­¢", "system")
        
        # å„²å­˜å¿«å–
        if self.reply_cache:
            self.reply_cache.save_cache_now()
            self._log_ui("ğŸ’¾ å¿«å–å·²å„²å­˜")
        
        # åœæ­¢ç›£è½ä»»å‹™
        if self._listen_task and not self._listen_task.done():
            self._listen_task.cancel()
            try:
                await self._listen_task
            except asyncio.CancelledError:
                pass
        
        # åœæ­¢éŸ³è¨Šæ•ç²
        if self._capture_task and not self._capture_task.done():
            self._capture_task.cancel()
            try:
                await self._capture_task
            except asyncio.CancelledError:
                pass
        
        # ç°¡åŒ–ç‰ˆï¼šä¸éœ€è¦é—œé–‰éŸ³è¨Šæµ
        self._audio_stream = None
        
        # æ¸…ç†ä»»å‹™å¼•ç”¨
        self._listen_task = None
        self._capture_task = None
        
        self._add_chat_message("ğŸ”‡ èªéŸ³æ§åˆ¶å·²åœæ­¢", "system")
        self._update_status("èªéŸ³æ§åˆ¶æœªå•Ÿå‹•", "main")
        self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
    
    def force_reset(self):
        """å¼·åˆ¶é‡ç½®ç‹€æ…‹ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
        self._running = False
        self._starting = False
        self._listen_task = None
        self._capture_task = None
        self._audio_stream = None
        self._log_ui("ğŸ”„ èªéŸ³æ§åˆ¶ç‹€æ…‹å·²å¼·åˆ¶é‡ç½®")
    
    def _check_dependencies(self) -> bool:
        """æª¢æŸ¥ä¾è³´å¥—ä»¶"""
        if not self.client:
            self._log_ui("âŒ OpenAI å®¢æˆ¶ç«¯æœªåˆå§‹åŒ–")
            return False
        
        if sd is None:
            self._log_ui("âŒ sounddevice æœªå®‰è£")
            return False
        
        if not WEBRTCVAD_AVAILABLE:
            self._log_ui("âš ï¸ webrtcvad æœªå®‰è£ï¼Œå°‡ä½¿ç”¨å›ºå®šæ™‚é•·éŒ„éŸ³")
        
        if self.config.enable_rules and not RULES_AVAILABLE:
            self._log_ui("âš ï¸ è¦å‰‡ç³»çµ±ä¾è³´æœªå®‰è£ï¼ˆpyyaml, rapidfuzzï¼‰")
        
        return True
    
    async def _setup_audio_stream(self):
        """è¨­å®šéŸ³è¨Šæµï¼ˆç°¡åŒ–ç‰ˆï¼Œé¿å…è¤‡é›œçš„éŸ³è¨Šæµè™•ç†ï¼‰"""
        try:
            # æª¢æŸ¥éŸ³è¨Šè£ç½®
            try:
                devices = sd.query_devices()
                if self.input_device is not None:
                    if self.input_device >= len(devices):
                        self._log_ui(f"âš ï¸ éŸ³è¨Šè£ç½®ç´¢å¼• {self.input_device} è¶…å‡ºç¯„åœï¼Œä½¿ç”¨é è¨­è£ç½®")
                        self.input_device = None
                    elif devices[self.input_device].get('max_input_channels', 0) == 0:
                        self._log_ui(f"âš ï¸ è£ç½® {self.input_device} ä¸æ”¯æ´è¼¸å…¥ï¼Œä½¿ç”¨é è¨­è£ç½®")
                        self.input_device = None
            except Exception as e:
                self._log_ui(f"âš ï¸ æŸ¥è©¢éŸ³è¨Šè£ç½®å¤±æ•—ï¼š{e}")
                self.input_device = None
            
            self._log_ui(f"ğŸ¤ éŸ³è¨Šè£ç½®è¨­å®šï¼šæ¡æ¨£ç‡ {self.config.audio.sample_rate}Hzï¼Œè£ç½® {self.input_device or 'default'}")
            
            # ç°¡åŒ–ç‰ˆï¼šä¸ä½¿ç”¨è¤‡é›œçš„éŸ³è¨Šæµï¼Œæ”¹ç‚ºæŒ‰éœ€éŒ„éŸ³
            self._log_ui("âœ… éŸ³è¨Šç³»çµ±åˆå§‹åŒ–å®Œæˆï¼ˆç°¡åŒ–æ¨¡å¼ï¼‰")
            
        except Exception as e:
            self._log_ui(f"âŒ éŸ³è¨Šç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
            raise RuntimeError(f"éŸ³è¨Šç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
    
    async def _capture_loop(self):
        """éŸ³è¨Šæ•ç²å¾ªç’°ï¼ˆç°¡åŒ–ç‰ˆï¼Œæ”¹ç‚ºæŒ‰éœ€éŒ„éŸ³ï¼‰"""
        # ç°¡åŒ–ç‰ˆï¼šä¸ä½¿ç”¨æŒçºŒçš„éŸ³è¨Šæ•ç²ï¼Œæ”¹ç‚ºæŒ‰éœ€éŒ„éŸ³
        while self._running:
            try:
                # ç­‰å¾…éŒ„éŸ³è«‹æ±‚
                await asyncio.sleep(0.1)
            except asyncio.CancelledError:
                break
            except Exception as e:
                self._log_ui(f"âš ï¸ éŸ³è¨Šæ•ç²å¾ªç’°éŒ¯èª¤ï¼š{e}")
                await asyncio.sleep(0.1)
    
    async def _listen_loop(self):
        """èªéŸ³ç›£è½ä¸»å¾ªç’°ï¼ˆç°¡åŒ–ç‰ˆï¼Œæ”¹ç‚ºæŒ‰éœ€éŒ„éŸ³ï¼‰"""
        self._log_ui("ğŸ™ï¸ é–‹å§‹èªéŸ³ç›£è½å¾ªç’°...")
        consecutive_failures = 0
        max_failures = 5  # æœ€å¤šé€£çºŒå¤±æ•—5æ¬¡å¾Œåœæ­¢
        
        # ç¢ºä¿åœ¨å¾ªç’°é–‹å§‹å‰æª¢æŸ¥ç‹€æ…‹
        if not self._running:
            self._log_ui("âš ï¸ ç›£è½å¾ªç’°å•Ÿå‹•æ™‚ç™¼ç¾ _running ç‚º False")
            return
        
        while self._running:
            try:
                # æª¢æŸ¥é‹è¡Œç‹€æ…‹
                if not self._running:
                    self._log_ui("ğŸ›‘ æª¢æ¸¬åˆ°åœæ­¢ä¿¡è™Ÿï¼Œé€€å‡ºç›£è½å¾ªç’°")
                    break
                
                self._log_ui("ğŸ”„ ç›£è½å¾ªç’°ï¼šæº–å‚™éŒ„éŸ³...")
                
                # ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨å›ºå®šæ™‚é•·éŒ„éŸ³ï¼Œé¡ä¼¼ç°¡åŒ–ç‰ˆçš„æ–¹å¼
                audio_data = await self._record_audio_simple()
                
                # å†æ¬¡æª¢æŸ¥é‹è¡Œç‹€æ…‹
                if not self._running:
                    self._log_ui("ğŸ›‘ éŒ„éŸ³å®Œæˆå¾Œæª¢æ¸¬åˆ°åœæ­¢ä¿¡è™Ÿï¼Œé€€å‡ºç›£è½å¾ªç’°")
                    break
                
                if not audio_data:
                    consecutive_failures += 1
                    self._log_ui(f"âš ï¸ éŒ„éŸ³å¤±æ•— ({consecutive_failures}/{max_failures})ï¼Œç­‰å¾…2ç§’å¾Œé‡è©¦...")
                    if consecutive_failures >= max_failures:
                        self._log_ui("âŒ éŒ„éŸ³é€£çºŒå¤±æ•—æ¬¡æ•¸éå¤šï¼Œåœæ­¢èªéŸ³æ§åˆ¶")
                        break
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’å¾Œå†æ¬¡å˜—è©¦
                    continue
                
                # é‡ç½®å¤±æ•—è¨ˆæ•¸
                consecutive_failures = 0
                self._log_ui(f"âœ… éŒ„éŸ³æˆåŠŸï¼Œæ•¸æ“šå¤§å°ï¼š{len(audio_data)} bytes")
                
                # èªéŸ³è­˜åˆ¥
                self._log_ui("ğŸ”„ é–‹å§‹èªéŸ³è­˜åˆ¥...")
                text = await self._transcribe_audio(audio_data)
                
                # å†æ¬¡æª¢æŸ¥é‹è¡Œç‹€æ…‹
                if not self._running:
                    self._log_ui("ğŸ›‘ èªéŸ³è­˜åˆ¥å®Œæˆå¾Œæª¢æ¸¬åˆ°åœæ­¢ä¿¡è™Ÿï¼Œé€€å‡ºç›£è½å¾ªç’°")
                    break
                
                if not text.strip():
                    self._log_ui("âš ï¸ èªéŸ³è­˜åˆ¥çµæœç‚ºç©ºï¼Œç­‰å¾…2ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’å¾Œå†æ¬¡å˜—è©¦
                    continue
                
                self._log_ui(f"ğŸ¤ è­˜åˆ¥çµæœï¼š{text}")
                
                # è™•ç†æŒ‡ä»¤
                self._log_ui("ğŸ”„ é–‹å§‹è™•ç†æŒ‡ä»¤...")
                await self._process_command(text)
                
                # è™•ç†å®Œä¸€å€‹æŒ‡ä»¤å¾Œç­‰å¾…ä¸€æ®µæ™‚é–“
                self._log_ui("âœ… æŒ‡ä»¤è™•ç†å®Œæˆï¼Œç­‰å¾…3ç§’å¾Œç¹¼çºŒç›£è½...")
                await asyncio.sleep(3)
                
            except asyncio.CancelledError:
                self._log_ui("ğŸ›‘ ç›£è½å¾ªç’°è¢«å–æ¶ˆ")
                break
            except Exception as e:
                consecutive_failures += 1
                self._log_ui(f"âš ï¸ è™•ç†èªéŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤ ({consecutive_failures}/{max_failures})ï¼š{e}")
                if consecutive_failures >= max_failures:
                    self._log_ui("âŒ éŒ¯èª¤æ¬¡æ•¸éå¤šï¼Œåœæ­¢èªéŸ³æ§åˆ¶")
                    break
                await asyncio.sleep(2)
    
    async def _record_audio(self) -> Optional[bytes]:
        """éŒ„éŸ³ä¸¦è¿”å›éŸ³è¨Šæ•¸æ“š"""
        audio_buffer = []
        max_buffer_size = 1000  # é™åˆ¶ç·©è¡å€å¤§å°
        
        try:
            if self._vad and WEBRTCVAD_AVAILABLE:
                # ä½¿ç”¨ VAD è‡ªå‹•åœæ­¢éŒ„éŸ³
                consecutive_silence = 0
                has_speech = False
                speech_frames = 0
                
                frame_size = int(self.config.audio.sample_rate * 
                               self.config.audio.frame_duration_ms / 1000)
                silence_frames = int(self.config.audio.silence_ms / 
                                   self.config.audio.frame_duration_ms)
                
                timeout_count = 0
                max_timeouts = 50  # æœ€å¤šç­‰å¾… 5 ç§’
                
                while self._running and timeout_count < max_timeouts:
                    try:
                        # ç­‰å¾…éŸ³è¨Šæ•¸æ“š
                        data = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                        timeout_count = 0  # é‡ç½®è¶…æ™‚è¨ˆæ•¸
                        
                        # å®‰å…¨åœ°è½‰æ›ç‚º numpy array
                        try:
                            audio_frame = np.frombuffer(data, dtype=np.int16)
                        except Exception as e:
                            self._log_ui(f"âš ï¸ éŸ³è¨Šæ•¸æ“šè½‰æ›å¤±æ•—ï¼š{e}")
                            continue
                        
                        # VAD æª¢æ¸¬
                        if len(audio_frame) >= frame_size:
                            try:
                                frame_bytes = audio_frame[:frame_size].tobytes()
                                is_speech = self._vad.is_speech(frame_bytes, 
                                                              self.config.audio.sample_rate)
                                
                                if is_speech:
                                    consecutive_silence = 0
                                    has_speech = True
                                    speech_frames += 1
                                else:
                                    consecutive_silence += 1
                                
                                # é™åˆ¶ç·©è¡å€å¤§å°é¿å…è¨˜æ†¶é«”å•é¡Œ
                                if len(audio_buffer) < max_buffer_size:
                                    audio_buffer.append(audio_frame)
                                else:
                                    # ç§»é™¤æœ€èˆŠçš„å¹€
                                    audio_buffer.pop(0)
                                    audio_buffer.append(audio_frame)
                                
                                # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åœæ­¢éŒ„éŸ³
                                if (has_speech and 
                                    speech_frames >= self.config.audio.min_speech_frames and 
                                    consecutive_silence >= silence_frames):
                                    break
                                
                                # é˜²æ­¢éŒ„éŸ³éé•·
                                if len(audio_buffer) * self.config.audio.frame_duration_ms > self.config.audio.max_recording_ms:
                                    break
                                    
                            except Exception as e:
                                self._log_ui(f"âš ï¸ VAD æª¢æ¸¬å¤±æ•—ï¼š{e}")
                                continue
                        
                    except asyncio.TimeoutError:
                        timeout_count += 1
                        continue
                    except Exception as e:
                        self._log_ui(f"âš ï¸ éŒ„éŸ³æ•¸æ“šè™•ç†éŒ¯èª¤ï¼š{e}")
                        break
            else:
                # å›ºå®šæ™‚é•·éŒ„éŸ³ï¼ˆ2ç§’ï¼Œæ¸›å°‘æ™‚é–“ï¼‰
                duration = 2.0
                frames_needed = min(int(duration * self.config.audio.sample_rate / 4000), max_buffer_size)
                
                for _ in range(frames_needed):
                    try:
                        data = await asyncio.wait_for(self._audio_queue.get(), timeout=0.1)
                        try:
                            audio_frame = np.frombuffer(data, dtype=np.int16)
                            audio_buffer.append(audio_frame)
                        except Exception as e:
                            self._log_ui(f"âš ï¸ éŸ³è¨Šå¹€è™•ç†éŒ¯èª¤ï¼š{e}")
                            continue
                    except asyncio.TimeoutError:
                        continue
                    except Exception as e:
                        self._log_ui(f"âš ï¸ å›ºå®šæ™‚é•·éŒ„éŸ³éŒ¯èª¤ï¼š{e}")
                        break
            
            # åˆä½µéŸ³è¨Šæ•¸æ“š
            if audio_buffer:
                try:
                    full_audio = np.concatenate(audio_buffer, axis=0)
                    audio_bytes = full_audio.tobytes()
                    
                    # æ¸…ç†è¨˜æ†¶é«”
                    del audio_buffer
                    del full_audio
                    
                    return audio_bytes
                except Exception as e:
                    self._log_ui(f"âš ï¸ éŸ³è¨Šåˆä½µå¤±æ•—ï¼š{e}")
                    return None
            
            return None
            
        except Exception as e:
            self._log_ui(f"âš ï¸ éŒ„éŸ³éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            # æ¸…ç†è¨˜æ†¶é«”
            if audio_buffer:
                del audio_buffer
            return None
    
    async def _record_audio_simple(self) -> Optional[bytes]:
        """éŒ„éŸ³æ–¹æ³•ï¼ˆå„ªå…ˆä½¿ç”¨ VADï¼Œå‚™é¸å›ºå®šæ™‚é•·ï¼‰"""
        try:
            # å¦‚æœæœ‰ VADï¼Œä½¿ç”¨ VAD éŒ„éŸ³
            if self._vad and WEBRTCVAD_AVAILABLE:
                return await self._record_with_vad()
            else:
                # å‚™é¸ï¼šå›ºå®šæ™‚é•·éŒ„éŸ³
                return await self._record_fixed_duration()
            
        except Exception as e:
            self._log_ui(f"âš ï¸ éŒ„éŸ³å¤±æ•—ï¼š{e}")
            return None
    
    async def _record_with_vad(self) -> Optional[bytes]:
        """ä½¿ç”¨ VAD è‡ªå‹•åµæ¸¬èªéŸ³çµæŸçš„éŒ„éŸ³æ–¹æ³•"""
        try:
            # æª¢æŸ¥ VAD æ˜¯å¦æ­£ç¢ºåˆå§‹åŒ–
            if not self._vad:
                self._log_ui("âŒ VAD æœªåˆå§‹åŒ–ï¼Œç„¡æ³•ä½¿ç”¨ VAD éŒ„éŸ³")
                return None
            
            self._log_ui("ğŸ¤ é–‹å§‹ VAD éŒ„éŸ³ï¼Œåµæ¸¬åˆ°éœéŸ³æ™‚è‡ªå‹•åœæ­¢...")
            
            def record_with_vad():
                """VAD éŒ„éŸ³å‡½æ•¸ï¼ˆåƒè€ƒ main.py çš„å¯¦ç¾ï¼‰"""
                try:
                    # è¨­å®š sounddevice åƒæ•¸
                    if self.input_device is not None:
                        sd.default.device = (self.input_device, None)
                    sd.default.samplerate = self.config.audio.sample_rate
                    sd.default.channels = self.config.audio.channels
                    
                    # VAD åƒæ•¸
                    frame_duration_ms = self.config.audio.frame_duration_ms
                    frame_size = int(self.config.audio.sample_rate * frame_duration_ms / 1000)
                    silence_frames = int(self.config.audio.silence_ms / frame_duration_ms)
                    min_speech_frames = self.config.audio.min_speech_frames
                    
                    # é–‹å§‹éŒ„éŸ³
                    audio_buffer = []
                    consecutive_silence = 0
                    has_speech = False
                    speech_frames = 0
                    
                    with sd.InputStream(samplerate=self.config.audio.sample_rate,
                                      channels=self.config.audio.channels,
                                      dtype="int16", blocksize=frame_size) as stream:
                        while True:
                            # è®€å–ä¸€å¹€éŸ³è¨Š
                            audio_frame, overflowed = stream.read(frame_size)
                            if overflowed:
                                print("âš ï¸ éŸ³è¨Šç·©è¡å€æº¢å‡º")
                            
                            # è½‰æ›ç‚º bytes ä¾› VAD ä½¿ç”¨
                            frame_bytes = audio_frame.tobytes()
                            
                            # VAD åµæ¸¬
                            is_speech = self._vad.is_speech(frame_bytes, self.config.audio.sample_rate)
                            
                            if is_speech:
                                consecutive_silence = 0
                                has_speech = True
                                speech_frames += 1
                            else:
                                consecutive_silence += 1
                            
                            # å„²å­˜éŸ³è¨Šå¹€
                            audio_buffer.append(audio_frame)
                            
                            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åœæ­¢
                            if (has_speech and 
                                speech_frames >= min_speech_frames and 
                                consecutive_silence >= silence_frames):
                                print("ğŸ”‡ åµæ¸¬åˆ°éœéŸ³ï¼Œåœæ­¢éŒ„éŸ³")
                                break
                            
                            # é˜²æ­¢éŒ„éŸ³éé•·
                            if len(audio_buffer) * frame_duration_ms > self.config.audio.max_recording_ms:
                                print("â° éŒ„éŸ³æ™‚é–“éé•·ï¼Œè‡ªå‹•åœæ­¢")
                                break
                    
                    # åˆä½µéŸ³è¨Š
                    if audio_buffer:
                        full_audio = np.concatenate(audio_buffer, axis=0)
                        return full_audio
                    else:
                        return None
                        
                except Exception as e:
                    raise RuntimeError(f"VAD éŒ„éŸ³éç¨‹å¤±æ•—ï¼š{e}")
            
            # åœ¨åŸ·è¡Œç·’ä¸­åŸ·è¡ŒéŒ„éŸ³
            loop = asyncio.get_running_loop()
            try:
                audio = await asyncio.wait_for(
                    loop.run_in_executor(None, record_with_vad),
                    timeout=30.0  # æœ€å¤š30ç§’è¶…æ™‚
                )
                
                if audio is not None and len(audio) > 0:
                    audio_bytes = audio.tobytes()
                    self._log_ui(f"âœ… VAD éŒ„éŸ³å®Œæˆï¼Œæ•¸æ“šå¤§å°ï¼š{len(audio_bytes)} bytes")
                    return audio_bytes
                else:
                    self._log_ui("âš ï¸ VAD éŒ„éŸ³æ•¸æ“šç‚ºç©º")
                    return None
                    
            except asyncio.TimeoutError:
                self._log_ui("âš ï¸ VAD éŒ„éŸ³è¶…æ™‚")
                return None
            
        except Exception as e:
            self._log_ui(f"âš ï¸ VAD éŒ„éŸ³å¤±æ•—ï¼š{e}")
            return None
    
    async def _record_fixed_duration(self) -> Optional[bytes]:
        """å›ºå®šæ™‚é•·éŒ„éŸ³æ–¹æ³•ï¼ˆå‚™é¸æ–¹æ¡ˆï¼‰"""
        try:
            duration = 3.0  # 3ç§’éŒ„éŸ³
            sample_rate = self.config.audio.sample_rate
            
            self._log_ui(f"ğŸ¤ é–‹å§‹å›ºå®šæ™‚é•·éŒ„éŸ³ {duration} ç§’...")
            
            def record_audio():
                """éŒ„éŸ³å‡½æ•¸"""
                try:
                    # è¨­å®š sounddevice é è¨­åƒæ•¸
                    if self.input_device is not None:
                        sd.default.device = (self.input_device, None)
                    sd.default.samplerate = sample_rate
                    sd.default.channels = self.config.audio.channels
                    
                    # é–‹å§‹éŒ„éŸ³
                    audio = sd.rec(int(duration * sample_rate), dtype="int16")
                    
                    # ç­‰å¾…éŒ„éŸ³å®Œæˆ
                    import time
                    time.sleep(duration)
                    
                    return audio
                except Exception as e:
                    raise RuntimeError(f"å›ºå®šæ™‚é•·éŒ„éŸ³éç¨‹å¤±æ•—ï¼š{e}")
            
            # åœ¨åŸ·è¡Œç·’ä¸­åŸ·è¡ŒéŒ„éŸ³
            loop = asyncio.get_running_loop()
            try:
                audio = await asyncio.wait_for(
                    loop.run_in_executor(None, record_audio),
                    timeout=duration + 5.0
                )
                
                if audio is not None and len(audio) > 0:
                    audio_bytes = audio.tobytes()
                    self._log_ui(f"âœ… å›ºå®šæ™‚é•·éŒ„éŸ³å®Œæˆï¼Œæ•¸æ“šå¤§å°ï¼š{len(audio_bytes)} bytes")
                    return audio_bytes
                else:
                    self._log_ui("âš ï¸ å›ºå®šæ™‚é•·éŒ„éŸ³æ•¸æ“šç‚ºç©º")
                    return None
                    
            except asyncio.TimeoutError:
                self._log_ui("âš ï¸ å›ºå®šæ™‚é•·éŒ„éŸ³è¶…æ™‚")
                return None
            
        except Exception as e:
            self._log_ui(f"âš ï¸ å›ºå®šæ™‚é•·éŒ„éŸ³å¤±æ•—ï¼š{e}")
            return None
    
    async def _transcribe_audio(self, audio_data: bytes) -> str:
        """ä½¿ç”¨ Whisper API è½‰éŒ„éŸ³è¨Š"""
        if not self.client:
            return ""
        
        self._update_status("ASRèªéŸ³è½‰éŒ„ä¸­...", "processing")
        temp_path = None
        try:
            # æª¢æŸ¥éŸ³è¨Šæ•¸æ“š
            if not audio_data or len(audio_data) < 1000:  # å¤ªçŸ­çš„éŸ³è¨Š
                return ""
            
            # å°‡éŸ³è¨Šæ•¸æ“šä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
            import tempfile
            import time
            temp_path = f"temp_audio_{int(time.time())}.wav"
            
            try:
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                if len(audio_array) == 0:
                    return ""
                
                wavwrite(temp_path, self.config.audio.sample_rate, audio_array)
                
                # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸå‰µå»º
                if not os.path.exists(temp_path) or os.path.getsize(temp_path) < 1000:
                    return ""
                    
            except Exception as e:
                self._log_ui(f"âš ï¸ éŸ³è¨Šæ–‡ä»¶å‰µå»ºå¤±æ•—ï¼š{e}")
                return ""
            
            # ä½¿ç”¨ Whisper API
            try:
                with open(temp_path, "rb") as audio_file:
                    transcript = await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: self.client.audio.transcriptions.create(
                            model=self.config.whisper_model,
                            file=audio_file,
                            language=self.config.whisper_language,
                            response_format="text"
                        )
                    )
                
                # è™•ç†è½‰éŒ„çµæœ
                if transcript:
                    text = transcript.strip() if isinstance(transcript, str) else str(transcript).strip()
                    if text:
                        # è½‰æ›ç‚ºç¹é«”ä¸­æ–‡
                        result = s2twp(text)
                        return result
                        
            except Exception as e:
                self._log_ui(f"âš ï¸ Whisper API èª¿ç”¨å¤±æ•—ï¼š{e}")
                return ""
            
            return ""
            
        except Exception as e:
            self._log_ui(f"âš ï¸ èªéŸ³è½‰éŒ„éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return ""
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except Exception:
                    pass
    
    async def _process_command(self, text: str):
        """è™•ç†èªéŸ³æŒ‡ä»¤ï¼ˆæ•´åˆæ‰€æœ‰æ–°åŠŸèƒ½ï¼‰"""
        # é¡¯ç¤ºç”¨æˆ¶èªéŸ³è¼¸å…¥
        self._add_chat_message(text, "user")
        self._update_status("LLMåˆ†æä¸­...", "processing")
        
        # 1. æª¢æŸ¥æ¨¡å¼åˆ‡æ›ï¼ˆå„ªå…ˆè™•ç†ï¼‰
        mode_switch_reply = self.mode_manager.check_mode_switch(text)
        if mode_switch_reply:
            self._add_chat_message(f"ğŸ”„ æ¨¡å¼åˆ‡æ›ï¼š{mode_switch_reply}", "system")
            if self.config.enable_tts:
                self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                await self._speak_text(mode_switch_reply)
            self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
            return
        
        # 2. æª¢æŸ¥å¿«å–å›è¦†
        if self.reply_cache:
            cached_reply = self.reply_cache.get_cached_reply(text)
            if cached_reply:
                self._add_chat_message("âš¡ ä½¿ç”¨å¿«å–å›è¦†", "system")
                self._add_chat_message(cached_reply, "ai")
                if self.config.enable_tts:
                    self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                    await self._speak_text(cached_reply)
                
                # é æ¸¬å¾ŒçºŒå¯èƒ½çš„å•é¡Œ
                if self.preload_manager:
                    self.reply_cache.predict_and_preload(text, self.conversation_history)
                self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
                return
        
        # 3. æª¢æŸ¥å¸¸ç”¨å›è¦†æ¨¡æ¿
        if self.reply_cache:
            common_reply = self.reply_cache.get_common_reply(text)
            if common_reply:
                self._add_chat_message("ğŸ“‹ ä½¿ç”¨å¸¸ç”¨å›è¦†æ¨¡æ¿", "system")
                self._add_chat_message(common_reply, "ai")
                if self.config.enable_tts:
                    self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                    await self._speak_text(common_reply)
                
                # å¿«å–é€™å€‹å›è¦†
                self.reply_cache.cache_reply(text, common_reply)
                
                # é æ¸¬å¾ŒçºŒå¯èƒ½çš„å•é¡Œ
                if self.preload_manager:
                    self.reply_cache.predict_and_preload(text, self.conversation_history)
                self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
                return
        
        # 4. æª¢æŸ¥å–šé†’è©
        wake_word = "å•Ÿå‹•èªéŸ³ç™¼çƒæ©Ÿ"
        if self._is_wake_word(text, wake_word):
            self._add_chat_message(f"ğŸ”” å–šé†’è©å‘½ä¸­ï¼š{wake_word}", "system")
            reply_text = "å½¥æ¾¤æ‚¨å¥½ï¼Œæˆ‘æ˜¯ä½ çš„æ™ºæ…§ç¾½çƒç™¼çƒæ©ŸåŠ©ç†ï¼Œä»Šå¤©æƒ³ç·´ä»€éº¼å‘¢ï¼Ÿ"
            self._add_chat_message(reply_text, "ai")
            
            # å¿«å–å›è¦†
            if self.reply_cache:
                self.reply_cache.cache_reply(text, reply_text)
            
            if self.config.enable_tts:
                self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                await self._speak_text(reply_text)
            self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
            return
        
        # 5. è¦å‰‡åŒ¹é…
        if self.rule_matcher:
            self._add_chat_message("ğŸ” é–‹å§‹è¦å‰‡åŒ¹é…...", "system")
            rule = self.rule_matcher.match(text)
            if rule:
                self._add_chat_message(f"âœ… æ‰¾åˆ°åŒ¹é…è¦å‰‡ï¼š{rule.get('id', 'unknown')}", "system")
                await self._handle_rule_match(rule, text)
                return
            else:
                self._add_chat_message("âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„è¦å‰‡", "system")
        else:
            self._add_chat_message("âš ï¸ è¦å‰‡åŒ¹é…å™¨æœªåˆå§‹åŒ–", "system")
        
        # 6. LLM å›è¦†ï¼ˆåªæœ‰åœ¨æ€è€ƒæ¨¡å¼ä¸‹æ‰ä½¿ç”¨ï¼‰
        if self.mode_manager.is_think_mode():
            self._add_chat_message("ğŸ¤– ä½¿ç”¨ LLM ç”Ÿæˆå›è¦†...", "system")
            self._update_status("LLMæ€è€ƒä¸­...", "processing")
            try:
                # ä½¿ç”¨ LLM ç”Ÿæˆå›è¦†
                system_prompt = "ä½ æ˜¯ç¾½çƒç™¼çƒæ©ŸåŠ©ç†ï¼Œè«‹ç”¨ç°¡æ½”çš„1-2å¥è©±å›è¦†ã€‚"
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ]
                
                # æ·»åŠ å°è©±æ­·å²
                if self.conversation_history:
                    messages = [{"role": "system", "content": system_prompt}] + self.conversation_history[-10:] + [{"role": "user", "content": text}]
                
                response = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        temperature=0.5,
                        max_tokens=120
                    )
                )
                
                reply_text = response.choices[0].message.content.strip()
                self._add_chat_message(reply_text, "ai")
                
                # å¿«å–å›è¦†
                if self.reply_cache:
                    self.reply_cache.cache_reply(text, reply_text)
                
                # æ›´æ–°å°è©±æ­·å²
                self.conversation_history.append({"role": "user", "content": text})
                self.conversation_history.append({"role": "assistant", "content": reply_text})
                
                # é™åˆ¶å°è©±æ­·å²é•·åº¦
                if len(self.conversation_history) > 20:
                    self.conversation_history = self.conversation_history[-20:]
                
                if self.config.enable_tts:
                    self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                    await self._speak_text(reply_text)
                self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
                return
                
            except Exception as e:
                self._add_chat_message(f"âŒ LLM å›è¦†å¤±æ•—ï¼š{e}", "error")
        
        # 7. æ§åˆ¶æ¨¡å¼ä¸‹è¦å‰‡ä¸åŒ¹é…æ™‚çš„å›è¦†
        if self.mode_manager.is_control_mode():
            reply_text = self.mode_manager.get_mismatch_reply()
            self._add_chat_message(reply_text, "ai")
            if self.config.enable_tts:
                self._update_status("TTSèªéŸ³åˆæˆä¸­...", "processing")
                await self._speak_text(reply_text)
        else:
            # æ€è€ƒæ¨¡å¼ä¸‹ä¹Ÿæ²’æœ‰ç”Ÿæˆå›è¦†
            self._add_chat_message("â“ æœªè­˜åˆ¥çš„æŒ‡ä»¤ï¼Œè«‹ä½¿ç”¨æ˜ç¢ºçš„ç¾½çƒè¨“ç·´æŒ‡ä»¤", "system")
        
        self._update_status("ç­‰å¾…èªéŸ³è¼¸å…¥...", "processing")
    
    def _is_wake_word(self, text: str, wake_word: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºå–šé†’è©ï¼ˆKWSï¼‰"""
        # ç§»é™¤ç©ºç™½å’Œæ¨™é»ç¬¦è™Ÿé€²è¡Œæ¯”è¼ƒ
        def normalize_text(s: str) -> str:
            import re
            # ç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œç©ºç™½
            s = re.sub(r'[^\w\u4e00-\u9fff]', '', s.lower())
            return s
        
        normalized_text = normalize_text(text)
        normalized_wake = normalize_text(wake_word)
        
        return normalized_wake in normalized_text
    
    async def _handle_rule_match(self, rule: dict, original_text: str):
        """è™•ç†è¦å‰‡åŒ¹é…çµæœ"""
        rule_id = rule.get("id", "unknown")
        action = rule.get("action", "")
        reply_config = rule.get("reply", {})
        reply_text = reply_config.get("text", "")
        voice = reply_config.get("voice", self.config.default_voice)
        
        self._log_ui(f"âœ… åŒ¹é…è¦å‰‡ï¼š{rule_id}")
        self._log_ui(f"ğŸ’¬ å›è¦†ï¼š{reply_text}")
        
        # å¿«å–è¦å‰‡åŒ¹é…çµæœ
        if self.reply_cache:
            self.reply_cache.cache_rule_result(original_text, rule)
            self.reply_cache.cache_reply(original_text, reply_text)
        
        # TTS èªéŸ³å›è¦†
        if self.config.enable_tts and reply_text:
            await self._speak_text(reply_text, voice)
        
        # æ›´æ–°å°è©±æ­·å²
        self.conversation_history.append({"role": "user", "content": original_text})
        self.conversation_history.append({"role": "assistant", "content": reply_text})
        
        # é™åˆ¶å°è©±æ­·å²é•·åº¦
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
        
        # é æ¸¬å¾ŒçºŒå¯èƒ½çš„å•é¡Œ
        if self.preload_manager:
            self.reply_cache.predict_and_preload(original_text, self.conversation_history)
        
        # åŸ·è¡Œå‹•ä½œ
        await self._execute_action(action, rule, original_text)
    
    async def _speak_text(self, text: str, voice: str = None):
        """TTS èªéŸ³åˆæˆä¸¦æ’­æ”¾"""
        if not self.client or not text:
            return
        
        try:
            voice = voice or self.config.default_voice
            output_path = "temp_speech.mp3"
            
            # ç”ŸæˆèªéŸ³
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.audio.speech.create(
                    model="tts-1",
                    voice=voice,
                    input=text,
                    speed=self.config.default_speed
                )
            )
            
            # ä¿å­˜éŸ³è¨Šæ–‡ä»¶
            with open(output_path, "wb") as f:
                f.write(response.content)
            
            # æ’­æ”¾éŸ³è¨Šï¼ˆmacOSï¼‰
            import subprocess
            try:
                subprocess.run(["afplay", output_path], check=False)
            except Exception:
                pass
            
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            if os.path.exists(output_path):
                os.remove(output_path)
                
        except Exception as e:
            self._log_ui(f"âš ï¸ TTS èªéŸ³åˆæˆå¤±æ•—ï¼š{e}")
    
    async def _execute_action(self, action: str, rule: dict, original_text: str):
        """åŸ·è¡Œå‹•ä½œ"""
        if not action:
            return
        
        try:
            # æ ¹æ“šå‹•ä½œé¡å‹åŸ·è¡Œç›¸æ‡‰çš„ç™¼çƒæ©Ÿæ§åˆ¶
            if action == "scan_device":
                await self._scan_device()
            elif action == "connect_device":
                await self._connect_device()
            elif action == "disconnect_device":
                await self._disconnect_device()
            elif action == "start_training":
                await self._start_training()
            elif action == "stop_training":
                await self._stop_training()
            elif action.startswith("set_speed_"):
                speed = action.split("_")[-1]  # fast, slow, medium
                await self._set_speed(speed)
            elif action.endswith("_training"):
                training_type = action.replace("_training", "")
                await self._start_specific_training(training_type)
            elif action.startswith("adjust_"):
                await self._adjust_setting(action, rule)
            else:
                self._log_ui(f"ğŸ”§ åŸ·è¡Œå‹•ä½œï¼š{action}")
                
        except Exception as e:
            self._log_ui(f"âš ï¸ åŸ·è¡Œå‹•ä½œå¤±æ•—ï¼š{e}")
    
    async def _scan_device(self):
        """æƒæç™¼çƒæ©Ÿ"""
        try:
            self._log_ui("ğŸ” é–‹å§‹æƒæç™¼çƒæ©Ÿ...")
            if hasattr(self.window, 'scan_devices'):
                await self.window.scan_devices()
            else:
                self._log_ui("âš ï¸ æƒæåŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            self._log_ui(f"âŒ æƒæå¤±æ•—ï¼š{e}")

    async def _connect_device(self):
        """é€£æ¥ç™¼çƒæ©Ÿ"""
        try:
            self._log_ui("ğŸ”— é–‹å§‹é€£æ¥ç™¼çƒæ©Ÿ...")
            if hasattr(self.window, 'connect_device'):
                await self.window.connect_device()
            else:
                self._log_ui("âš ï¸ é€£æ¥åŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            self._log_ui(f"âŒ é€£æ¥å¤±æ•—ï¼š{e}")

    async def _disconnect_device(self):
        """æ–·é–‹ç™¼çƒæ©Ÿé€£æ¥"""
        try:
            self._log_ui("âŒ æ–·é–‹ç™¼çƒæ©Ÿé€£æ¥...")
            if hasattr(self.window, 'disconnect_device'):
                await self.window.disconnect_device()
            else:
                self._log_ui("âš ï¸ æ–·é–‹åŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            self._log_ui(f"âŒ æ–·é–‹å¤±æ•—ï¼š{e}")

    async def _start_training(self):
        """é–‹å§‹è¨“ç·´"""
        if not hasattr(self.window, 'bluetooth_thread') or not self.window.bluetooth_thread:
            self._log_ui("âš ï¸ è«‹å…ˆé€£æ¥ç™¼çƒæ©Ÿ")
            return
        
        if not getattr(self.window.bluetooth_thread, 'is_connected', False):
            self._log_ui("âš ï¸ ç™¼çƒæ©Ÿæœªé€£æ¥")
            return
        
        # é–‹å§‹åŸºæœ¬è¨“ç·´æ¨¡å¼
        self._log_ui("ğŸ¸ é–‹å§‹ç¾½çƒè¨“ç·´...")
        # é€™è£¡å¯ä»¥èª¿ç”¨ç¾æœ‰çš„è¨“ç·´é‚è¼¯
    
    async def _stop_training(self):
        """åœæ­¢è¨“ç·´"""
        if hasattr(self.window, 'stop_flag'):
            self.window.stop_flag = True
        self._log_ui("â¹ï¸ åœæ­¢è¨“ç·´")
    
    async def _set_speed(self, speed: str):
        """è¨­å®šç™¼çƒé€Ÿåº¦"""
        speed_map = {
            "fast": "é«˜é€Ÿ",
            "slow": "ä½é€Ÿ", 
            "medium": "ä¸­é€Ÿ"
        }
        self._log_ui(f"âš¡ è¨­å®šç™¼çƒé€Ÿåº¦ï¼š{speed_map.get(speed, speed)}")
    
    async def _start_specific_training(self, training_type: str):
        """é–‹å§‹ç‰¹å®šé¡å‹çš„è¨“ç·´"""
        training_map = {
            "front_court": "å‰å ´ç·´ç¿’",
            "back_court": "å¾Œå ´ç·´ç¿’",
            "smash": "æ®ºçƒç·´ç¿’",
            "drop_shot": "åŠçƒç·´ç¿’",
            "multi_ball": "å¤šçƒç·´ç¿’",
            "single_ball": "å–®çƒç·´ç¿’"
        }
        self._log_ui(f"ğŸ¯ é–‹å§‹{training_map.get(training_type, training_type)}")
    
    async def _adjust_setting(self, action: str, rule: dict):
        """èª¿æ•´è¨­å®š"""
        self._log_ui(f"âš™ï¸ èª¿æ•´è¨­å®šï¼š{action}")
    
    def _log_ui(self, message: str):
        """è¨˜éŒ„åˆ°UIï¼ˆä¿®å¾©ç‰ˆï¼Œæ”¯æ´ç•°æ­¥ç’°å¢ƒï¼‰"""
        # å…ˆåœ¨çµ‚ç«¯è¼¸å‡ºï¼Œç¢ºä¿èƒ½çœ‹åˆ°è™•ç†éç¨‹
        print(f"[èªéŸ³æ§åˆ¶] {message}")
        
        try:
            # åœ¨ç•°æ­¥ç’°å¢ƒä¸­ï¼Œä½¿ç”¨ç·šç¨‹å®‰å…¨çš„æ–¹å¼æ›´æ–°UI
            import threading
            from PyQt5.QtCore import QTimer
            
            def update_ui():
                try:
                    if hasattr(self.window, "voice_chat_log") and self.window.voice_chat_log is not None:
                        self.window.voice_chat_log.append(message)
                        self.window.voice_chat_log.ensureCursorVisible()
                    elif hasattr(self.window, "text_chat_log") and self.window.text_chat_log is not None:
                        self.window.text_chat_log.append(message)
                        self.window.text_chat_log.ensureCursorVisible()
                    elif hasattr(self.window, "log_message"):
                        self.window.log_message(message)
                except Exception as e:
                    print(f"UIæ›´æ–°å¤±æ•—ï¼š{e}")
            
            # ä½¿ç”¨QTimerä¾†ç¢ºä¿åœ¨ä¸»ç·šç¨‹ä¸­åŸ·è¡ŒUIæ›´æ–°
            try:
                from PyQt5.QtCore import QTimer
                QTimer.singleShot(0, update_ui)
            except Exception:
                # å¦‚æœQTimerä¸å¯ç”¨ï¼Œç›´æ¥èª¿ç”¨
                update_ui()
                
        except Exception as e:
            print(f"æ—¥èªŒè¨˜éŒ„å¤±æ•—ï¼š{e}")
    
    def _update_status(self, status: str, status_type: str = "processing"):
        """æ›´æ–°ç‹€æ…‹é¡¯ç¤º"""
        try:
            # ç›´æ¥åœ¨ç•¶å‰ç·šç¨‹ä¸­æ›´æ–°UIï¼Œé¿å…QTimerå•é¡Œ
            if hasattr(self.window, "update_voice_status"):
                try:
                    self.window.update_voice_status(status, status_type)
                except Exception as e:
                    print(f"ç‹€æ…‹æ›´æ–°å¤±æ•—ï¼š{e}")
                
        except Exception as e:
            print(f"ç‹€æ…‹æ›´æ–°ç•°å¸¸ï¼š{e}")
    
    def _add_chat_message(self, message: str, message_type: str = "system"):
        """æ·»åŠ èŠå¤©è¨Šæ¯"""
        try:
            # ç›´æ¥åœ¨ç•¶å‰ç·šç¨‹ä¸­æ›´æ–°UIï¼Œé¿å…QTimerå•é¡Œ
            if hasattr(self.window, "add_voice_chat_message"):
                try:
                    self.window.add_voice_chat_message(message, message_type)
                except Exception as e:
                    print(f"èŠå¤©è¨Šæ¯æ›´æ–°å¤±æ•—ï¼š{e}")
                    # å›é€€åˆ°èˆŠçš„æ—¥èªŒæ–¹æ³•
                    self._log_ui(message)
            else:
                # å›é€€åˆ°èˆŠçš„æ—¥èªŒæ–¹æ³•
                self._log_ui(message)
                
        except Exception as e:
            print(f"èŠå¤©è¨Šæ¯æ›´æ–°ç•°å¸¸ï¼š{e}")
            # ç¢ºä¿è‡³å°‘èƒ½åœ¨çµ‚ç«¯çœ‹åˆ°è¨Šæ¯
            self._log_ui(message)


# === æ—¥èªŒç³»çµ± ===
def setup_logging(level: str = "INFO"):
    """è¨­å®šæ—¥èªŒç³»çµ±"""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('badminton_tts.log'),
            logging.StreamHandler()
        ]
    )

# è¼”åŠ©å‡½æ•¸
def format_reply(template: str, context: dict) -> str:
    """æ ¼å¼åŒ–å›è¦†æ¨¡æ¿"""
    try:
        return template.format(**context)
    except Exception:
        return template  # ç¼ºå°‘è®Šæ•¸å°±ç”¨åŸæ¨£

# å‘å¾Œç›¸å®¹çš„å‡½æ•¸
def create_voice_control(window, **kwargs):
    """å‰µå»ºèªéŸ³æ§åˆ¶å¯¦ä¾‹ï¼ˆå‘å¾Œç›¸å®¹ï¼‰"""
    config = VoiceConfig()
    
    # æ‡‰ç”¨åƒæ•¸
    if 'model_path' in kwargs:
        # å¿½ç•¥èˆŠçš„ model_pathï¼Œä½¿ç”¨ Whisper API
        pass
    if 'input_device' in kwargs:
        device = kwargs['input_device']
    else:
        device = None
    
    voice_control = VoiceControlTTS(window, config)
    if device is not None:
        voice_control.set_input_device(device)
    
    return voice_control
