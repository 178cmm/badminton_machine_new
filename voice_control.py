"""
ğŸ¸ ç¾½çƒç™¼çƒæ©ŸèªéŸ³æ§åˆ¶ç³»çµ±ï¼ˆèˆŠç‰ˆ - åŸºæ–¼ Vosk æœ¬åœ°æ¨¡å‹ï¼‰

âš ï¸ æ³¨æ„ï¼šæ­¤æª”æ¡ˆç‚ºèˆŠç‰ˆèªéŸ³æ§åˆ¶ç³»çµ±ï¼ŒåŸºæ–¼ Vosk æœ¬åœ°èªéŸ³è­˜åˆ¥æ¨¡å‹ã€‚
æ–°ç‰ˆæœ¬å·²æ•´åˆ Whisper API + è¦å‰‡åŒ¹é… + TTS èªéŸ³å›è¦†ï¼Œè«‹ä½¿ç”¨ voice_control_tts.py

æ–°ç‰ˆæœ¬åŠŸèƒ½ï¼š
- Whisper API é«˜æº–ç¢ºåº¦èªéŸ³è­˜åˆ¥
- æ™ºèƒ½è¦å‰‡åŒ¹é…ç³»çµ±  
- TTS èªéŸ³å›è¦†
- é è¼‰å…¥å¿«å–å„ªåŒ–
- èˆ‡ç™¼çƒæ©Ÿæ§åˆ¶ç³»çµ±æ·±åº¦æ•´åˆ

æ–°ç‰ˆæœ¬ä½¿ç”¨æ–¹å¼ï¼š
1. åœ¨ GUI çš„èªéŸ³æ§åˆ¶é é¢è¨­å®š OpenAI API Key
2. é¸æ“‡éŸ³è¨Šè£ç½®å’ŒèªéŸ³è¨­å®š
3. é»æ“Šå•Ÿå‹•èªéŸ³æ§åˆ¶
4. ä½¿ç”¨è‡ªç„¶èªè¨€æŒ‡ä»¤æ§åˆ¶ç™¼çƒæ©Ÿ

æ”¯æ´çš„èªéŸ³æŒ‡ä»¤ï¼š
- é–‹å§‹è¨“ç·´ / åœæ­¢è¨“ç·´
- å¿«é€Ÿç™¼çƒ / æ…¢é€Ÿç™¼çƒ / ä¸­é€Ÿç™¼çƒ
- å‰å ´ç·´ç¿’ / å¾Œå ´ç·´ç¿’ / æ®ºçƒç·´ç¿’
- å·¦é‚Š / å³é‚Š / ä¸­é–“ / æé«˜ / é™ä½
- æ›´å¤šæŒ‡ä»¤è«‹åƒè€ƒ rules/badminton_rules.yaml

æœ¬æª”æ¡ˆä¿ç•™ç”¨æ–¼å‘å¾Œç›¸å®¹æ€§ï¼Œå»ºè­°ä½¿ç”¨æ–°ç‰ˆæœ¬åŠŸèƒ½ã€‚
"""

import asyncio
import json
import re
import sys
import shutil
from typing import Optional, List

try:
    from vosk import Model, KaldiRecognizer
except Exception:  # pragma: no cover - é¿å…æœªå®‰è£æ™‚ç›´æ¥å´©æ½°
    Model = None  # type: ignore
    KaldiRecognizer = None  # type: ignore

try:
    import sounddevice as sd
except Exception:  # pragma: no cover
    sd = None  # type: ignore


SHOT_NAMES: List[str] = [
    "æ­£æ‰‹é«˜é çƒ", "åæ‰‹é«˜é çƒ",
    "æ­£æ‰‹åˆ‡çƒ", "åæ‰‹åˆ‡çƒ",
    "æ­£æ‰‹æ®ºçƒ", "åæ‰‹æ®ºçƒ",
    "æ­£æ‰‹å¹³æŠ½çƒ", "åæ‰‹å¹³æŠ½çƒ",
    "æ­£æ‰‹å°çƒ", "åæ‰‹å°çƒ",
    "æ­£æ‰‹æŒ‘çƒ", "åæ‰‹æŒ‘çƒ",
    "å¹³æ¨çƒ",
    "æ­£æ‰‹æ¥æ®ºçƒ", "åæ‰‹æ¥æ®ºçƒ",
    "è¿‘èº«æ¥æ®º",
]

_TRAD_TO_SIMP = {
    "é ": "è¿œ",
    "é¡†": "é¢—",
    "æ®º": "æ€",
    "é–“": "é—´",
}

def to_simplified(text: str) -> str:
    return "".join(_TRAD_TO_SIMP.get(ch, ch) for ch in text)

def to_traditional(text: str) -> str:
    inv = {v: k for k, v in _TRAD_TO_SIMP.items()}
    return "".join(inv.get(ch, ch) for ch in text)


class VoiceControl:
    """
    ä»¥ Vosk + Grammar å¯¦ä½œçš„èªéŸ³æ§åˆ¶ã€‚
    - éåŒæ­¥ç›£è½éº¥å…‹é¢¨ï¼Œä¸é˜»å¡ PyQt5 + qasync ä¸»åŸ·è¡Œç·’
    - Grammar åƒ…å…è¨±ï¼šçƒç¨®åç¨±ã€æ•¸å­— 1~100ã€ã€Œé¡†ã€ã€Œé–“éš”ã€ã€Œç§’ã€é—œéµå­—
    - è§£æå®Œæˆå¾Œï¼Œç›´æ¥å‘¼å«ç¾æœ‰ç™¼çƒæµç¨‹ï¼ˆé€é window.bluetooth_thread / send_shotï¼‰
    - æ–¼ UI çš„ `text_chat_log` é¡¯ç¤ºæœ€å¾Œä¸€æ¬¡è¾¨è­˜èˆ‡è§£æçµæœï¼ˆè‹¥å­˜åœ¨ï¼‰
    """

    def __init__(self, window, model_path: str = "models/vosk-model-small-cn-0.22", samplerate: int = 16000, input_device: Optional[int] = None, use_grammar: bool = False, backend: str = "auto", ffmpeg_audio_index: Optional[int] = None):
        self.window = window
        self.model_path = model_path
        self.samplerate = samplerate
        self.input_device = input_device
        self.use_grammar = use_grammar
        self.backend = backend  # auto | sounddevice | ffmpeg
        self.ffmpeg_audio_index = ffmpeg_audio_index if ffmpeg_audio_index is not None else 0

        self._model = None
        self._recognizer = None
        self._audio_stream = None
        self._running = False
        self._starting = False
        self._audio_queue: asyncio.Queue = asyncio.Queue()
        self._listen_task: Optional[asyncio.Task] = None
        self._execute_task: Optional[asyncio.Task] = None
        self._capture_task: Optional[asyncio.Task] = None
        self._start_stop_lock = asyncio.Lock()
        self._sentence_buffer: str = ""
        self._last_sentence_ts: float = 0.0
        self._ffmpeg_process = None
        self._audio_seen_logged = False

        # æ§‹å»º Grammar å­—å½™
        self._grammar_words = self._build_grammar_words()

    def _build_grammar_words(self) -> List[str]:
        words: List[str] = []
        # åƒ…ä½¿ç”¨ç°¡é«”å–®å­—ï¼Œé¿å… small-cn æ¨¡å‹ OOVï¼ˆå¿½ç•¥ç¹é«”å–®å­—ï¼‰
        charset = set()
        for name in SHOT_NAMES:
            for ch in to_simplified(name):
                charset.add(ch)
        for ch in ["é¢—", "ç§’", "é—´", "éš”", "é«˜", "è¿œ", "æ‰‹", "å", "æ­£", "çƒ", "æ¥", "æ€", "å¹³", "æŠ½", "æŒ‘", "è¿‘", "èº«", "åˆ‡"]:
            charset.add(ch)
        for ch in ["é›¶", "ã€‡", "ä¸€", "äºŒ", "ä¸¤", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å", "ç™¾"]:
            charset.add(ch)
        for d in "0123456789":
            charset.add(d)
        words.extend(sorted(charset))
        
        # å»é‡
        seen = set()
        deduped = []
        for w in words:
            if w not in seen:
                seen.add(w)
                deduped.append(w)
        return deduped

    async def start(self):
        """å•Ÿå‹•èªéŸ³ç›£è½ã€‚"""
        # é˜²é‡å…¥èˆ‡ç«¶æ…‹
        if self._running or self._starting:
            return
        async with self._start_stop_lock:
            if self._running or self._starting:
                return
            self._starting = True
        # è¼‰å…¥æ¨¡å‹
        if Model is None or KaldiRecognizer is None:
            self._log_ui("æœªå®‰è£ voskï¼Œè«‹å…ˆåœ¨ç’°å¢ƒä¸­å®‰è£ vosk å¥—ä»¶ã€‚")
            self._starting = False
            return
        if sd is None and self.backend in ("auto", "sounddevice"):
            self._log_ui("æœªå®‰è£ sounddeviceï¼Œè«‹å…ˆåœ¨ç’°å¢ƒä¸­å®‰è£ sounddevice å¥—ä»¶æˆ–åˆ‡æ›åˆ° ffmpeg å¾Œç«¯ã€‚")
            self._starting = False
            return

        # åŸºæœ¬è·¯å¾‘æª¢æŸ¥èˆ‡æç¤º
        import os
        if not os.path.isdir(self.model_path):
            self._log_ui(
                f"æ‰¾ä¸åˆ° Vosk æ¨¡å‹è³‡æ–™å¤¾ï¼š{self.model_path}\n"
                "è«‹å…ˆä¸‹è¼‰ä¸¦è§£å£“å®˜æ–¹ä¸­æ–‡æ¨¡å‹ï¼ˆå»ºè­° small-cn-0.22ï¼‰ï¼Œ\n"
                "å°‡æ•´å€‹è³‡æ–™å¤¾ç½®æ–¼ä¸Šè¿°è·¯å¾‘ï¼Œæˆ–åœ¨å•Ÿå‹•æ™‚æä¾›æ­£ç¢ºçš„ model_pathï¼Œ\n"
                "æˆ–è¨­å®šç’°å¢ƒè®Šæ•¸ VOSK_MODEL_PATH æŒ‡å‘æ¨¡å‹è³‡æ–™å¤¾ã€‚\n"
                "ä¸‹è¼‰é é¢ï¼š" + "https://alphacephei.com/vosk/models"
            )
            self._starting = False
            return

        try:
            self._model = Model(self.model_path)
        except Exception as e:
            self._log_ui(f"è¼‰å…¥ Vosk æ¨¡å‹å¤±æ•—ï¼š{e}")
            self._starting = False
            return

        if self.use_grammar:
            grammar_json = json.dumps(self._grammar_words, ensure_ascii=False)
            self._recognizer = KaldiRecognizer(self._model, self.samplerate, grammar_json)
        else:
            self._recognizer = KaldiRecognizer(self._model, self.samplerate)

        # é¸æ“‡éŸ³è¨Šå¾Œç«¯
        # macOS é è¨­å„ªå…ˆä½¿ç”¨ sounddeviceï¼Œé¿å… ffmpeg æ¬Šé™/è£ç½®ç´¢å¼•å•é¡Œ
        chosen_backend = self.backend
        if chosen_backend == "auto":
            chosen_backend = "sounddevice"
        self._log_ui(f"éŸ³è¨Šå¾Œç«¯ï¼š{chosen_backend}ï¼Œæ¡æ¨£ç‡ï¼š{self.samplerate}ï¼Œè£ç½®ï¼š{self.input_device if self.input_device is not None else 'default'}")

        if chosen_backend == "sounddevice":
            try:
                stream_kwargs = dict(
                    samplerate=self.samplerate,
                    blocksize=8000,
                    dtype="int16",
                    channels=1,
                )
                if self.input_device is not None:
                    stream_kwargs["device"] = self.input_device
                self._audio_stream = sd.RawInputStream(**stream_kwargs)
                self._audio_stream.start()
            except Exception as e:
                self._log_ui(f"é–‹å•Ÿéº¥å…‹é¢¨å¤±æ•—ï¼ˆsounddeviceï¼‰ï¼š{e}ï¼Œå˜—è©¦ä»¥ ffmpeg å¾Œç«¯é‡è©¦â€¦")
                # ç«‹å³å˜—è©¦å›é€€åˆ° ffmpeg
                chosen_backend = "ffmpeg"
            else:
                self._running = True
                self._capture_task = asyncio.create_task(self._capture_loop())
        else:
            # ä½¿ç”¨ ffmpeg å¾Œç«¯ï¼ˆmacOS: avfoundationï¼‰
            if sys.platform == "darwin":
                cmd = [
                    "ffmpeg", "-hide_banner", "-loglevel", "error",
                    "-f", "avfoundation",
                    "-i", f":{int(self.ffmpeg_audio_index)}",
                    "-ac", "1",
                    "-ar", str(int(self.samplerate)),
                    "-f", "s16le", "-",
                ]
            else:
                # å…¶ä»–å¹³å°å¯è¦–éœ€æ±‚æ“´å……ï¼ˆé è¨­å˜—è©¦ defaultï¼‰
                cmd = [
                    "ffmpeg", "-hide_banner", "-loglevel", "error",
                    "-f", "alsa" if sys.platform.startswith("linux") else "dshow",
                    "-i", "default" if sys.platform.startswith("linux") else "audio=default",
                    "-ac", "1",
                    "-ar", str(int(self.samplerate)),
                    "-f", "s16le", "-",
                ]
            try:
                self._ffmpeg_process = await asyncio.create_subprocess_exec(
                    *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
                )
            except Exception as e:
                self._log_ui(f"å•Ÿå‹• ffmpeg å¤±æ•—ï¼š{e}ï¼Œæ”¹ç”¨ sounddevice å¾Œç«¯é‡è©¦ã€‚")
                # fallback to sounddevice
                try:
                    if sd is None:
                        raise RuntimeError("sounddevice æœªå®‰è£")
                    stream_kwargs = dict(
                        samplerate=self.samplerate,
                        blocksize=8000,
                        dtype="int16",
                        channels=1,
                    )
                    if self.input_device is not None:
                        stream_kwargs["device"] = self.input_device
                    self._audio_stream = sd.RawInputStream(**stream_kwargs)
                    self._audio_stream.start()
                    self._running = True
                    self._capture_task = asyncio.create_task(self._capture_loop())
                except Exception as e2:
                    self._log_ui(f"sounddevice å¾Œç«¯ä¹Ÿå•Ÿå‹•å¤±æ•—ï¼š{e2}")
                    self._starting = False
                    return
            if not self._audio_stream:
                self._running = True
                self._capture_task = asyncio.create_task(self._ffmpeg_capture_loop())

        self._listen_task = asyncio.create_task(self._listen_loop())
        self._log_ui("èªéŸ³æ§åˆ¶ï¼šå·²å•Ÿå‹•ï¼Œè«‹èªªå‡ºæŒ‡ä»¤ï¼Œä¾‹å¦‚ã€æ­£æ‰‹é«˜é çƒ 20 é¡† é–“éš” 3 ç§’ã€ã€‚")
        self._starting = False

    async def stop(self):
        """åœæ­¢èªéŸ³ç›£è½ä¸¦é‡‹æ”¾è³‡æºã€‚"""
        async with self._start_stop_lock:
            if not self._running and not self._starting:
                return
            # å°‡ starting ç‹€æ…‹ä¹Ÿä¸€ä½µä¸­æ­¢
            self._starting = False
        self._running = False
        if self._listen_task and not self._listen_task.done():
            self._listen_task.cancel()
            try:
                await self._listen_task
            except asyncio.CancelledError:
                pass
        self._listen_task = None

        if self._capture_task and not self._capture_task.done():
            self._capture_task.cancel()
            try:
                await self._capture_task
            except asyncio.CancelledError:
                pass
        self._capture_task = None

        if self._audio_stream is not None:
            try:
                self._audio_stream.stop()
                self._audio_stream.close()
            except Exception:
                pass
            self._audio_stream = None
        if self._ffmpeg_process is not None:
            try:
                self._ffmpeg_process.terminate()
            except Exception:
                pass
            self._ffmpeg_process = None

        # åœæ­¢ä»»ä½•ä»åœ¨åŸ·è¡Œçš„ç™¼çƒä»»å‹™
        if self._execute_task and not self._execute_task.done():
            self._execute_task.cancel()
            try:
                await self._execute_task
            except asyncio.CancelledError:
                pass
        self._execute_task = None

        self._log_ui("èªéŸ³æ§åˆ¶ï¼šå·²åœæ­¢ã€‚")

    async def _capture_loop(self):
        # ä»¥é˜»å¡è®€çš„æ–¹å¼å¾ PortAudio æ“·å–è³‡æ–™ï¼Œé¿å…ä½¿ç”¨ Python callbackï¼ˆcffiï¼‰
        while self._running and self._audio_stream is not None:
            try:
                # å°‡é˜»å¡ I/O ä¸Ÿåˆ°èƒŒæ™¯åŸ·è¡Œç·’ï¼Œé¿å…å¡ä½äº‹ä»¶åœˆ
                loop = asyncio.get_running_loop()
                data, _overflowed = await loop.run_in_executor(None, self._audio_stream.read, 8000)
                if data:
                    try:
                        if not self._audio_seen_logged:
                            self._audio_seen_logged = True
                            self._log_ui("å·²é–‹å§‹æ¥æ”¶éº¥å…‹é¢¨éŸ³è¨Šâ€¦")
                        self._audio_queue.put_nowait(bytes(data))
                    except Exception:
                        pass
            except asyncio.CancelledError:
                break
            except Exception:
                # è®€å–éŒ¯èª¤æ™‚ç¨ä½œå»¶é²é¿å…å¿™ç­‰
                await asyncio.sleep(0.01)

    async def _ffmpeg_capture_loop(self):
        if not self._ffmpeg_process or not self._ffmpeg_process.stdout:
            return
        while self._running:
            try:
                chunk = await self._ffmpeg_process.stdout.read(8000)
                if not chunk:
                    await asyncio.sleep(0.01)
                    continue
                try:
                    if not self._audio_seen_logged:
                        self._audio_seen_logged = True
                        self._log_ui("å·²é–‹å§‹æ¥æ”¶éº¥å…‹é¢¨éŸ³è¨Šï¼ˆffmpegï¼‰â€¦")
                    self._audio_queue.put_nowait(bytes(chunk))
                except Exception:
                    pass
            except asyncio.CancelledError:
                break
            except Exception:
                await asyncio.sleep(0.01)

    def _on_audio(self, indata, frames, time, status):  # sounddevice callbackï¼ˆåŸ·è¡Œæ–¼é asyncio åŸ·è¡Œç·’ï¼‰
        if not self._running:
            return
        if status:
            # å¯è¦–éœ€è¦è¼¸å‡ºç‹€æ…‹
            pass
        try:
            # å°‡ bytes ä¸Ÿå…¥ asyncio éšŠåˆ—
            self._audio_queue.put_nowait(bytes(indata))
        except Exception:
            pass

    async def _listen_loop(self):
        assert self._recognizer is not None
        while self._running:
            try:
                data = await self._audio_queue.get()
            except asyncio.CancelledError:
                break
            if not data:
                continue
            try:
                if self._recognizer.AcceptWaveform(data):
                    result_json = self._recognizer.Result()
                    self._handle_result_json(result_json)
                else:
                    # é¡¯ç¤º partial çµæœä»¥ä¾¿é™¤éŒ¯
                    try:
                        pj = json.loads(self._recognizer.PartialResult() or "{}")
                        partial = (pj.get("partial") or "").strip()
                        if partial:
                            self._log_ui(f"ï¼ˆéƒ¨åˆ†ï¼‰{partial}")
                    except Exception:
                        pass
            except Exception:
                # ä¿è­·æ€§è™•ç†ï¼Œé¿å… recognizer å´©æ½°
                continue

    def _handle_result_json(self, result_json: str):
        try:
            obj = json.loads(result_json)
        except Exception:
            return
        text = (obj.get("text") or "").strip()
        if not text:
            return
        # é¡¯ç¤ºåŸå§‹è¾¨è­˜æ–‡æœ¬
        self._log_ui(f"èªéŸ³ï¼š{text}")

        # è§£æï¼ˆåƒ…å…è¨± Grammar å­—å½™ï¼Œçµæ§‹ï¼š<çƒç¨®> [<æ•¸å­—> é¡†] [é–“éš” <æ•¸å­—> ç§’]ï¼‰
        # æ­£è¦åŒ–ï¼šç§»é™¤ç©ºç™½ã€ç°¡è½‰ç¹
        normalized = to_traditional(text.replace(" ", ""))
        parsed = self._parse_command_from_text(normalized)
        if not parsed:
            self._log_ui("ï¼ˆç„¡æ³•è§£æç‚ºæœ‰æ•ˆæŒ‡ä»¤ï¼‰")
            return

        self._log_ui(f"è§£æï¼š{parsed}")
        
        # è™•ç†æ¨¡æ“¬å°æ‰“æŒ‡ä»¤
        if parsed.get("type") == "start_simulation":
            self._execute_simulation_command(parsed)
        elif parsed.get("type") == "stop_simulation":
            self._execute_stop_simulation_command()
        else:
            # å•Ÿå‹•éé˜»å¡çš„ç™¼çƒæµç¨‹ï¼ˆé¿å…èˆ‡æ—¢æœ‰è¨“ç·´è¡çªï¼Œåªé€æŒ‡å®šé¡†æ•¸ï¼‰
            if self._execute_task and not self._execute_task.done():
                self._execute_task.cancel()
            self._execute_task = asyncio.create_task(self._execute_specific_shot(parsed["shot_name"], parsed["count"], parsed["interval"]))

    def _parse_command_from_text(self, text: str) -> Optional[dict]:
        # é¦–å…ˆæª¢æŸ¥æ˜¯å¦ç‚ºæ¨¡æ“¬å°æ‰“æŒ‡ä»¤
        simulation_result = self._parse_simulation_command(text)
        if simulation_result:
            return simulation_result
        
        # æ‰¾çƒç¨®ï¼ˆä»¥åŒ…å«é—œéµç‰‡æ®µç‚ºæº–ï¼‰
        shot_name = None
        for name in SHOT_NAMES:
            if name in text:
                shot_name = name
                break
        if not shot_name:
            return None

        # æ•¸é‡ï¼ˆé è¨­ 10 é¡†ï¼‰ã€‚å…ˆæŠ“é˜¿æ‹‰ä¼¯æ•¸å­—ï¼Œå†æŠ“ä¸­æ–‡æ•¸å­—
        count = self._extract_first_int_in_range(text, 1, 100)
        if count is None:
            count = self._extract_first_cn_number(text)
        if count is None:
            count = 10

        # é–“éš”ç§’æ•¸ï¼ˆé è¨­ 5 ç§’ï¼‰
        interval = self._extract_interval_seconds(text)
        if interval is None:
            interval = 5.0

        return {"shot_name": shot_name, "count": int(count), "interval": float(interval)}

    def _parse_simulation_command(self, text: str) -> Optional[dict]:
        """è§£ææ¨¡æ“¬å°æ‰“æŒ‡ä»¤"""
        # æ¨¡æ“¬å°æ‰“é—œéµå­—
        simulation_keywords = ["æ¨¡æ“¬å°æ‰“", "å°æ‰“æ¨¡å¼", "å°æ‰“", "æ¨¡æ“¬", "å°æˆ°", "å°ç·´"]
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ¨¡æ“¬å°æ‰“é—œéµå­—
        if not any(keyword in text for keyword in simulation_keywords):
            return None
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºåœæ­¢æŒ‡ä»¤
        stop_keywords = ["åœæ­¢", "çµæŸ", "æš«åœ"]
        if any(keyword in text for keyword in stop_keywords):
            return {"type": "stop_simulation"}
        
        # æå–ç­‰ç´š
        level = self._extract_simulation_level(text)
        if level is None:
            level = 1  # é è¨­ç­‰ç´š
        
        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨é›™ç™¼çƒæ©Ÿ
        dual_keywords = ["é›™ç™¼çƒæ©Ÿ", "å…©å°", "é›™æ©Ÿ", "é›™çƒæ©Ÿ", "å…©å°ç™¼çƒæ©Ÿ"]
        use_dual = any(keyword in text for keyword in dual_keywords)
        
        return {
            "type": "start_simulation",
            "level": level,
            "use_dual_machine": use_dual
        }
    
    def _extract_simulation_level(self, text: str) -> Optional[int]:
        """æå–æ¨¡æ“¬å°æ‰“ç­‰ç´š"""
        # ç›´æ¥åŒ¹é…æ•¸å­—
        level = self._extract_first_int_in_range(text, 1, 12)
        if level:
            return level
        
        # åŒ¹é…ä¸­æ–‡æ•¸å­—
        cn_level = self._extract_first_cn_number(text)
        if cn_level and 1 <= cn_level <= 12:
            return cn_level
        
        # åŒ¹é…ç­‰ç´šé—œéµå­—
        level_keywords = {
            "ä¸€": 1, "äºŒ": 2, "ä¸‰": 3, "å››": 4, "äº”": 5, "å…­": 6,
            "ä¸ƒ": 7, "å…«": 8, "ä¹": 9, "å": 10, "åä¸€": 11, "åäºŒ": 12
        }
        
        for keyword, level in level_keywords.items():
            if keyword in text:
                return level
        
        return None

    def _execute_simulation_command(self, parsed: dict):
        """åŸ·è¡Œæ¨¡æ“¬å°æ‰“æŒ‡ä»¤"""
        try:
            level = parsed.get("level", 1)
            use_dual = parsed.get("use_dual_machine", False)
            
            self._log_ui(f"é–‹å§‹æ¨¡æ“¬å°æ‰“ - ç­‰ç´š {level}" + (" (é›™ç™¼çƒæ©Ÿ)" if use_dual else ""))
            
            # å‰µå»ºæ¨¡æ“¬å°æ‰“åŸ·è¡Œå™¨
            if not hasattr(self.window, 'simulation_executor'):
                from core.executors.simulation_executor import create_simulation_executor
                self.window.simulation_executor = create_simulation_executor(self.window)
            
            # é–‹å§‹æ¨¡æ“¬å°æ‰“
            success = self.window.simulation_executor.start_simulation(level, use_dual)
            
            if success:
                self._log_ui(f"âœ… æ¨¡æ“¬å°æ‰“å·²é–‹å§‹ - ç­‰ç´š {level}")
            else:
                self._log_ui("âŒ é–‹å§‹æ¨¡æ“¬å°æ‰“å¤±æ•—")
                
        except Exception as e:
            self._log_ui(f"âŒ åŸ·è¡Œæ¨¡æ“¬å°æ‰“æŒ‡ä»¤æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _execute_stop_simulation_command(self):
        """åŸ·è¡Œåœæ­¢æ¨¡æ“¬å°æ‰“æŒ‡ä»¤"""
        try:
            self._log_ui("åœæ­¢æ¨¡æ“¬å°æ‰“")
            
            if hasattr(self.window, 'simulation_executor'):
                success = self.window.simulation_executor.stop_simulation()
                
                if success:
                    self._log_ui("âœ… æ¨¡æ“¬å°æ‰“å·²åœæ­¢")
                else:
                    self._log_ui("âŒ åœæ­¢æ¨¡æ“¬å°æ‰“å¤±æ•—")
            else:
                self._log_ui("âŒ æ²’æœ‰æ­£åœ¨é‹è¡Œçš„æ¨¡æ“¬å°æ‰“")
                
        except Exception as e:
            self._log_ui(f"âŒ åœæ­¢æ¨¡æ“¬å°æ‰“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    @staticmethod
    def _extract_first_int_in_range(text: str, min_v: int, max_v: int) -> Optional[int]:
        # å°‹æ‰¾ç¬¬ä¸€å€‹ 1~100 çš„æ•´æ•¸ï¼ˆç©ºç™½æˆ–ç„¡ç©ºç™½éƒ½å¯ï¼Œç”±æ–¼ä¸­æ–‡è¼¸å‡ºå¸¸ç‚ºä»¥ç©ºç™½åˆ†è©ï¼‰
        num = None
        token = ""
        for ch in text:
            if ch.isdigit():
                token += ch
            else:
                if token:
                    try:
                        n = int(token)
                        if min_v <= n <= max_v:
                            num = n
                            break
                    except Exception:
                        pass
                    token = ""
        if num is None and token:
            try:
                n = int(token)
                if min_v <= n <= max_v:
                    num = n
            except Exception:
                pass
        return num

    @staticmethod
    def _extract_interval_seconds(text: str) -> Optional[float]:
        # å˜—è©¦å°‹æ‰¾ã€Œé–“éš” X ç§’ã€æˆ–çµå°¾çš„ã€ŒX ç§’ã€
        # ç‚ºé¿å…å¼•å…¥ reï¼Œä½¿ç”¨ç°¡å–®å­—ä¸²è™•ç†
        if ("é–“éš”" in text or "é—´éš”" in text) and "ç§’" in text:
            try:
                after = text.split("é–“éš”", 1)[1] if "é–“éš”" in text else text.split("é—´éš”", 1)[1]
                segment = after.split("ç§’", 1)[0]
                # åœ¨ segment ä¸­æŠ“ç¬¬ä¸€å€‹æ•¸å­—
                token = ""
                for ch in segment:
                    if ch.isdigit() or ch == ".":
                        token += ch
                    elif token:
                        break
                if token:
                    return float(token)
            except Exception:
                pass
            # å˜—è©¦ä¸­æ–‡æ•¸å­—
            try:
                after = text.split("é–“éš”", 1)[1] if "é–“éš”" in text else text.split("é—´éš”", 1)[1]
                segment = after.split("ç§’", 1)[0]
                val = VoiceControl._parse_cn_numeral(segment)
                if val:
                    return float(val)
            except Exception:
                pass
        # å¾Œå‚™ï¼šä»»ä½•ã€ŒX ç§’ã€
        if "ç§’" in text:
            try:
                segment = text.split("ç§’", 1)[0]
                token = ""
                for ch in reversed(segment):
                    if ch.isdigit() or ch == ".":
                        token = ch + token
                    elif token:
                        break
                if token:
                    return float(token)
            except Exception:
                pass
            # ä¸­æ–‡æ•¸å­—
            try:
                segment = text.split("ç§’", 1)[0]
                # å–çµå°¾é€£çºŒä¸­æ–‡æ•¸å­—
                m = re.search(r"([é›¶ã€‡â—‹ä¸€äºŒå…©ä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+)$", segment)
                if m:
                    val = VoiceControl._parse_cn_numeral(m.group(1))
                    if val:
                        return float(val)
            except Exception:
                pass
        return None

    @staticmethod
    def _parse_cn_numeral(token: str) -> Optional[int]:
        token = (token or "").strip()
        if not token:
            return None
        cn_map = {"é›¶":0, "ã€‡":0, "â—‹":0, "ä¸€":1, "äºŒ":2, "å…©":2, "ä¸¤":2, "ä¸‰":3, "å››":4, "äº”":5, "å…­":6, "ä¸ƒ":7, "å…«":8, "ä¹":9}
        # ç°¡å–®æ”¯æ´åˆ° 100
        if token == "å":
            return 10
        if token == "ç™¾":
            return 100
        # XåY / Xå / åY
        if "å" in token:
            parts = token.split("å")
            if len(parts) == 2:
                left, right = parts
                left_val = cn_map.get(left, 1) if left != "" else 1
                right_val = cn_map.get(right, 0) if right != "" else 0
                return left_val * 10 + right_val
        # å–®å­—
        if token in cn_map:
            return cn_map[token]
        # å…¶ä»–å½¢å¼ç•¥é
        return None

    @staticmethod
    def _extract_first_cn_number(text: str) -> Optional[int]:
        m = re.search(r"([é›¶ã€‡â—‹ä¸€äºŒå…©ä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]{1,3})(é¡†|é¢—|çƒ|æ¬¡)?", text)
        if m:
            return VoiceControl._parse_cn_numeral(m.group(1))
        return None

    async def _execute_specific_shot(self, shot_name: str, count: int, interval: float):
        # é€éæ—¢æœ‰çš„ mapping å–å¾— section
        try:
            section = self.window.get_section_by_shot_name(shot_name)
        except Exception:
            section = None
        if not section:
            self._log_ui(f"æ‰¾ä¸åˆ°çƒç¨®å°æ‡‰ï¼š{shot_name}")
            return

        if not getattr(self.window, "bluetooth_thread", None):
            self._log_ui("è«‹å…ˆæƒæä¸¦é€£æ¥ç™¼çƒæ©Ÿã€‚")
            return
        if not getattr(self.window.bluetooth_thread, "is_connected", False):
            self._log_ui("è«‹å…ˆé€£æ¥ç™¼çƒæ©Ÿã€‚")
            return

        sent = 0
        try:
            for _ in range(count):
                # è‹¥å¤–éƒ¨åœ¨é€²è¡Œè¨“ç·´ï¼Œé¿å…äº’ç›¸å¹²æ“¾
                if getattr(self.window, "stop_flag", False):
                    self._log_ui("åµæ¸¬åˆ°åœæ­¢æ——æ¨™ï¼Œçµ‚æ­¢èªéŸ³ç™¼çƒæµç¨‹ã€‚")
                    break
                try:
                    await self.window.bluetooth_thread.send_shot(section)
                except Exception as e:
                    self._log_ui(f"ç™¼çƒå¤±æ•—ï¼š{e}")
                    break
                sent += 1
                self._log_ui(f"èªéŸ³ç™¼çƒï¼š{shot_name} ç¬¬ {sent} é¡†ï¼ˆ{section}ï¼‰")
                await asyncio.sleep(max(0.2, float(interval)))
        finally:
            self._log_ui(f"èªéŸ³ç™¼çƒå®Œæˆï¼š{shot_name} å…± {sent}/{count} é¡†ã€‚")

    def _log_ui(self, message: str):
        # å„ªå…ˆå¯«å…¥èªéŸ³æ§åˆ¶é ï¼›å…¶æ¬¡æ–‡æœ¬æ§åˆ¶ï¼›å¦å‰‡é€€å›ç³»çµ±æ—¥èªŒ
        try:
            if hasattr(self.window, "voice_chat_log") and self.window.voice_chat_log is not None:
                self.window.voice_chat_log.append(message)
                self.window.voice_chat_log.ensureCursorVisible()
            elif hasattr(self.window, "text_chat_log") and self.window.text_chat_log is not None:
                self.window.text_chat_log.append(message)
                self.window.text_chat_log.ensureCursorVisible()
            elif hasattr(self.window, "log_message"):
                self.window.log_message(message)
        except Exception:
            pass

